{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/mingu/OneDrive/바탕 화면/성균관대/리서치인턴/공부/RL_study/dreamer\n"
     ]
    }
   ],
   "source": [
    "%cd RL_study/dreamer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:28:52.825363: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-04 09:28:52.838239: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-04 09:28:52.846089: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-04 09:28:52.861292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-04 09:28:52.864940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-04 09:28:52.877278: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 09:28:53.549918: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "\n",
    "from tqdm import tqdm\n",
    "from models import *\n",
    "from logger import Logger\n",
    "\n",
    "\n",
    "env = gym.make('CarRacing-v2')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: 3, obs shape: (96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "action_dim = env.action_space.shape[0]\n",
    "obs_shape = env.observation_space.shape\n",
    "print(\"action space: \",action_dim,\", obs shape: \", obs_shape,sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(env,state_dim, transition_representation, agent,replay_buffer, num_episode, device, training=True):\n",
    "    print(\"collecting data...\")\n",
    "    score=0\n",
    "    for _ in tqdm(range(num_episode)):\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        experience = []\n",
    "        prev_state = torch.zeros(1, state_dim).to(device)\n",
    "        prev_deter = transition_representation.init_hidden(1).to(device)\n",
    "        prev_action = torch.zeros(1, action_dim).to(device)\n",
    "        with torch.no_grad():\n",
    "            while not done:\n",
    "                #obs(96x96x3) -> (3x96x96) -> (1x3x96x96)\n",
    "                obs = torch.tensor(obs, dtype=torch.float32).permute(2,0,1).unsqueeze(0).to(device)/255\n",
    "                # s_t-1, a_t-1, o_t-1 -> s_t\n",
    "                posterior_mean, posterior_std, prev_deter = transition_representation.posterior(prev_state, prev_action, prev_deter,obs)\n",
    "                cur_state = posterior_mean + posterior_std*torch.normal(0, 1, posterior_mean.size()).to(device)\n",
    "\n",
    "                action_mu, action_std = agent(cur_state, prev_deter)\n",
    "                eps = torch.normal(0, 1, (1,action_dim)).to(device)\n",
    "                if training:\n",
    "                    cur_action = torch.tanh(action_mu + action_std*eps)\n",
    "                else:\n",
    "                    cur_action = torch.tanh(action_mu)\n",
    "                next_obs, reward, terminated, truncated, info  = env.step(cur_action[0].cpu().numpy())\n",
    "                done = terminated or truncated\n",
    "                \n",
    "                experience.append((np.array(obs.squeeze(0).cpu()), np.array(cur_action.squeeze(0).detach().cpu()), reward, done))\n",
    "                \n",
    "                obs = next_obs\n",
    "                prev_state = cur_state\n",
    "                prev_action = cur_action\n",
    "                score+=reward\n",
    "        if training:\n",
    "            for exp in experience:\n",
    "                replay_buffer.push(exp)\n",
    "    return score/num_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_return(rewards, values, gamma, lambda_):\n",
    "    # rewards, values : (Horizon+1, seq*batch)\n",
    "    # 어렵다\n",
    "    V_lambda = torch.zeros_like(rewards, device=rewards.device)\n",
    "\n",
    "    H = rewards.shape[0] - 1\n",
    "    V_n = torch.zeros_like(rewards, device=rewards.device)\n",
    "    V_n[H] = values[H]\n",
    "    for n in range(1, H+1):\n",
    "        # n-step 계산 하기 위함\n",
    "        # 각 step의 value 목표\n",
    "        V_n[:-n] = (gamma ** n) * values[n:]\n",
    "        for k in range(1, n+1):\n",
    "            # n step의 reward 합 진행\n",
    "            if k == n:\n",
    "                V_n[:-n] += (gamma ** (n-1)) * rewards[k:]\n",
    "            else:\n",
    "                V_n[:-n] += (gamma ** (k-1)) * rewards[k:-n+k]\n",
    "\n",
    "        # add lambda_ weighted n-step target to compute lambda target\n",
    "        if n == H:\n",
    "            V_lambda += (lambda_ ** (H-1)) * V_n\n",
    "        else:\n",
    "            V_lambda += (1 - lambda_) * (lambda_ ** (n-1)) * V_n\n",
    "            \n",
    "    return V_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch,state_dim,deterministic_dim, device, transition_representation, reward_model, observation, actor, value, model_optimizer, actor_optimizer, critic_optimizer):\n",
    "    obs_seq = []\n",
    "    action_seq = []\n",
    "    reward_seq = []\n",
    "    #batch = batch, seq, (obs, action, reward, done)\n",
    "    for seq in batch:\n",
    "        obs_temp=[]\n",
    "        action_temp=[]\n",
    "        reward_temp=[]\n",
    "        for (obs, action, reward, done) in seq:\n",
    "            obs_temp.append(obs)\n",
    "            action_temp.append(action)\n",
    "            reward_temp.append(reward)\n",
    "        obs_seq.append(obs_temp)\n",
    "        action_seq.append(action_temp)\n",
    "        reward_seq.append(reward_temp)\n",
    "    obs_seq = torch.tensor(np.array(obs_seq), dtype=torch.float32).to(device)\n",
    "    action_seq = torch.tensor(np.array(action_seq), dtype=torch.float32).to(device)\n",
    "    reward_seq = torch.tensor(np.array(reward_seq), dtype=torch.float32).to(device)\n",
    "    batch_size, seq_len, _, _, _ = obs_seq.size()\n",
    "    \n",
    "    prev_deter = transition_representation.init_hidden(batch_size).to(device)\n",
    "    prev_state = torch.zeros(batch_size, state_dim).to(device)\n",
    "    \n",
    "    states = torch.zeros(seq_len,batch_size, state_dim).to(device)\n",
    "    deters = torch.zeros(seq_len,batch_size, deterministic_dim).to(device)\n",
    "    \n",
    "    beta=0.1 #kl조절\n",
    "    imagine_horizon=15\n",
    "    gamma=0.99\n",
    "    lambda_=0.95\n",
    "    kl_loss = 0\n",
    "    reconstruction_loss = 0\n",
    "    reward_loss = 0\n",
    "    \n",
    "    total_kl_loss = 0\n",
    "    total_reconstruction_loss = 0\n",
    "    total_reward_loss = 0\n",
    "    \n",
    "    action_prev = action_seq[:, 0].to(device)\n",
    "    total_loss=torch.zeros(1).to(device)\n",
    "    for t in range(1,seq_len):\n",
    "        obs = obs_seq[:, t].to(device)\n",
    "        action = action_seq[:, t].to(device)\n",
    "        reward = reward_seq[:, t].to(device)\n",
    "        prior_mean, prior_std, _ = transition_representation(prev_state, action_prev, prev_deter)\n",
    "        posterior_mean, posterior_std, cur_deter = transition_representation.posterior(prev_state, action_prev, prev_deter,obs)\n",
    "        \n",
    "        state = posterior_mean + posterior_std*torch.normal(0, 1, posterior_mean.size()).to(device)\n",
    "        obs_pred = observation(state, cur_deter)\n",
    "        reconstruction_loss = nn.functional.mse_loss(obs_pred, obs)\n",
    "        \n",
    "        \n",
    "        reward_pred = reward_model(state, cur_deter)\n",
    "        reward_pred = reward_pred.squeeze(1)\n",
    "        reward_loss = nn.functional.mse_loss(reward_pred, reward)\n",
    "        \n",
    "        prior = Normal(prior_mean, prior_std)\n",
    "        posterior = Normal(posterior_mean, posterior_std)\n",
    "        kl_loss = kl_divergence(posterior, prior).mean()\n",
    "\n",
    "        \n",
    "        total_loss += reconstruction_loss + reward_loss + beta*kl_loss\n",
    "\n",
    "        action_prev = action\n",
    "        prev_state = state\n",
    "        prev_deter = cur_deter\n",
    "        \n",
    "        states[t] = state\n",
    "        deters[t] = cur_deter\n",
    "        \n",
    "        total_kl_loss += kl_loss.item()\n",
    "        total_reconstruction_loss += reconstruction_loss.item()\n",
    "        total_reward_loss += reward_loss.item()\n",
    "    model_optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    model_optimizer.step()\n",
    "\n",
    "    \n",
    "    ##actor, critic 학습\n",
    "    \n",
    "    print(\"training actor, critic...\")\n",
    "    #states (seq, batch, state_dim) -> (seq*batch, state_dim)\n",
    "    #deters (seq, batch, deterministic_dim) -> (seq*batch, deterministic_dim)\n",
    "    states = states.view(-1, state_dim).detach()\n",
    "    deters = deters.view(-1, deterministic_dim).detach()\n",
    "    \n",
    "    imagined_states = [states]\n",
    "    imagined_deters = [deters]\n",
    "    \n",
    "    rewards = []\n",
    "    values = []\n",
    "    \n",
    "    \n",
    "    rewards.append(reward_model(states, deters).squeeze())\n",
    "    values.append(value(states, deters).squeeze())\n",
    "    \n",
    "    for t in range(1,imagine_horizon+1):\n",
    "        action_mu, action_std = actor(imagined_states[t-1], imagined_deters[t-1])\n",
    "        eps = torch.normal(0, 1, (action_mu.size())).to(device)\n",
    "        action = torch.tanh(action_mu + action_std*eps)\n",
    "        \n",
    "        prior_mean, prior_std, deter = transition_representation(imagined_states[t-1], action, imagined_deters[t-1])\n",
    "        state = prior_mean + prior_std*torch.normal(0, 1, prior_mean.size()).to(device)\n",
    "        \n",
    "        imagined_states.append(state)\n",
    "        imagined_deters.append(deter)\n",
    "        \n",
    "        rewards.append(reward_model(imagined_states[t], imagined_deters[t]).squeeze())\n",
    "        values.append( value(imagined_states[t], imagined_deters[t]).squeeze())\n",
    "    \n",
    "    imagined_states = torch.stack(imagined_states, dim=0)\n",
    "    imagined_deters = torch.stack(imagined_deters, dim=0)\n",
    "    values = torch.stack(values, dim=0)\n",
    "    rewards = torch.stack(rewards, dim=0)\n",
    "    \n",
    "    returns = lambda_return(rewards, values,0.99, 0.95)\n",
    "    \n",
    "    critic_loss = nn.functional.mse_loss(values[1:],returns[1:].detach())\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward(retain_graph=True)\n",
    "    torch.nn.utils.clip_grad_norm_(value.parameters(), max_norm=100)\n",
    "    critic_optimizer.step()\n",
    "    \n",
    "    actor_loss = -returns.mean()\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(actor.parameters(), max_norm=100)\n",
    "    actor_optimizer.step()\n",
    "    \n",
    "    print(\"actor loss: \",actor_loss.item(),\", critic loss: \",critic_loss.item(),sep='')\n",
    "    \n",
    "    return total_kl_loss/(seq_len-1), total_reconstruction_loss/(seq_len-1), total_reward_loss/(seq_len-1), actor_loss.item(), critic_loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "state_dim=64\n",
    "deterministic_dim=256\n",
    "model_lr=1e-4\n",
    "actor_critc_lr=1e-4\n",
    "transition_representation=TransitionRepresentationModel(state_dim, action_dim).to(device)\n",
    "observation=ObservationModel(state_dim,deterministic_dim, obs_shape[2]).to(device)\n",
    "reward=RewardModel(state_dim,deterministic_dim).to(device)\n",
    "\n",
    "agent=Agent(state_dim,deterministic_dim, action_dim).to(device)\n",
    "value=ValueModel(state_dim,deterministic_dim).to(device)\n",
    "\n",
    "model_params = list(transition_representation.parameters()) + list(observation.parameters()) + list(reward.parameters())\n",
    "model_optimizer = optim.Adam(model_params, lr=model_lr)\n",
    "actor_optimizer = optim.Adam(agent.parameters(), lr=actor_critc_lr)\n",
    "critic_optimizer = optim.Adam(value.parameters(), lr=actor_critc_lr)\n",
    "\n",
    "#state, action, reward, next_state, done 저장하고 sampling 가능\n",
    "replay_buffer = ReplayBufferSeq(100000)\n",
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting seed data...\n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:03<00:00, 12.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:35<00:00, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:30:36,637 global_step: 0,train_score: -45.385780615726496, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_604/1336153294.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  obs_seq = torch.tensor(obs_seq, dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_604/1336153294.py:55: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  reward_loss = nn.functional.mse_loss(reward_pred, reward)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training actor, critic...\n",
      "actor loss: 0.5180847644805908, critic loss: 0.28133466839790344\n",
      "2024-10-04 09:30:49,071 global_step: 0,epoch: 0, kl_loss: 0.0465136615046281, reconst_loss: 0.06141179153809742, reward_loss: 0.14672660635195064, actor_loss: 0.5180847644805908, critic_loss: 0.28133466839790344, \n",
      "training actor, critic...\n",
      "actor loss: 0.43933549523353577, critic loss: 0.182479128241539\n",
      "2024-10-04 09:30:59,367 global_step: 1,epoch: 0, kl_loss: 0.0455660763842871, reconst_loss: 0.06215268267052514, reward_loss: 0.2354550215235094, actor_loss: 0.43933549523353577, critic_loss: 0.182479128241539, \n",
      "training actor, critic...\n",
      "actor loss: 0.37368133664131165, critic loss: 0.11487583070993423\n",
      "2024-10-04 09:31:09,355 global_step: 2,epoch: 0, kl_loss: 0.04516511601490938, reconst_loss: 0.06195729986137273, reward_loss: 0.17653874023247282, actor_loss: 0.37368133664131165, critic_loss: 0.11487583070993423, \n",
      "training actor, critic...\n",
      "actor loss: 0.32428258657455444, critic loss: 0.07298120856285095\n",
      "2024-10-04 09:31:18,796 global_step: 3,epoch: 0, kl_loss: 0.0441518192112978, reconst_loss: 0.06142745577559179, reward_loss: 0.20007668492593328, actor_loss: 0.32428258657455444, critic_loss: 0.07298120856285095, \n",
      "training actor, critic...\n",
      "actor loss: 0.29835283756256104, critic loss: 0.05111924558877945\n",
      "2024-10-04 09:31:28,196 global_step: 4,epoch: 0, kl_loss: 0.04291084091350132, reconst_loss: 0.061475821827747384, reward_loss: 0.21882496707198418, actor_loss: 0.29835283756256104, critic_loss: 0.05111924558877945, \n",
      "training actor, critic...\n",
      "actor loss: 0.29013216495513916, critic loss: 0.04065272957086563\n",
      "2024-10-04 09:31:37,532 global_step: 5,epoch: 0, kl_loss: 0.0421098063044174, reconst_loss: 0.0611911416053772, reward_loss: 0.18878607049926507, actor_loss: 0.29013216495513916, critic_loss: 0.04065272957086563, \n",
      "training actor, critic...\n",
      "actor loss: 0.3047906756401062, critic loss: 0.03998854383826256\n",
      "2024-10-04 09:31:46,684 global_step: 6,epoch: 0, kl_loss: 0.041571514828282655, reconst_loss: 0.061418582666285186, reward_loss: 0.2016961033341988, actor_loss: 0.3047906756401062, critic_loss: 0.03998854383826256, \n",
      "training actor, critic...\n",
      "actor loss: 0.3386579155921936, critic loss: 0.04672728478908539\n",
      "2024-10-04 09:31:55,922 global_step: 7,epoch: 0, kl_loss: 0.04074916665974472, reconst_loss: 0.06132528147831255, reward_loss: 0.15522744952301895, actor_loss: 0.3386579155921936, critic_loss: 0.04672728478908539, \n",
      "training actor, critic...\n",
      "actor loss: 0.38298532366752625, critic loss: 0.05967637151479721\n",
      "2024-10-04 09:32:05,122 global_step: 8,epoch: 0, kl_loss: 0.03994812188213881, reconst_loss: 0.06114546620115942, reward_loss: 0.20805797256453304, actor_loss: 0.38298532366752625, critic_loss: 0.05967637151479721, \n",
      "training actor, critic...\n",
      "actor loss: 0.42478010058403015, critic loss: 0.07334720343351364\n",
      "2024-10-04 09:32:14,340 global_step: 9,epoch: 0, kl_loss: 0.03918565155900255, reconst_loss: 0.0608367453880456, reward_loss: 0.1971463663028363, actor_loss: 0.42478010058403015, critic_loss: 0.07334720343351364, \n",
      "training actor, critic...\n",
      "actor loss: 0.4670812487602234, critic loss: 0.08818645775318146\n",
      "2024-10-04 09:32:23,630 global_step: 10,epoch: 0, kl_loss: 0.03832682963384657, reconst_loss: 0.061056535995128204, reward_loss: 0.24212416259058733, actor_loss: 0.4670812487602234, critic_loss: 0.08818645775318146, \n",
      "training actor, critic...\n",
      "actor loss: 0.5040479302406311, critic loss: 0.10070832073688507\n",
      "2024-10-04 09:32:32,967 global_step: 11,epoch: 0, kl_loss: 0.03732384117415213, reconst_loss: 0.06100101928625788, reward_loss: 0.2137134322773057, actor_loss: 0.5040479302406311, critic_loss: 0.10070832073688507, \n",
      "training actor, critic...\n",
      "actor loss: 0.5419350862503052, critic loss: 0.11552239954471588\n",
      "2024-10-04 09:32:42,581 global_step: 12,epoch: 0, kl_loss: 0.03713965638331613, reconst_loss: 0.06029623138661287, reward_loss: 0.16238869900568104, actor_loss: 0.5419350862503052, critic_loss: 0.11552239954471588, \n",
      "training actor, critic...\n",
      "actor loss: 0.5751670002937317, critic loss: 0.12567053735256195\n",
      "2024-10-04 09:32:51,851 global_step: 13,epoch: 0, kl_loss: 0.03590707246651303, reconst_loss: 0.060133433843753775, reward_loss: 0.18083839396927126, actor_loss: 0.5751670002937317, critic_loss: 0.12567053735256195, \n",
      "training actor, critic...\n",
      "actor loss: 0.6019980907440186, critic loss: 0.13271966576576233\n",
      "2024-10-04 09:33:01,018 global_step: 14,epoch: 0, kl_loss: 0.03525555257837535, reconst_loss: 0.06033309647927479, reward_loss: 0.22131446393548834, actor_loss: 0.6019980907440186, critic_loss: 0.13271966576576233, \n",
      "training actor, critic...\n",
      "actor loss: 0.6283618211746216, critic loss: 0.13778826594352722\n",
      "2024-10-04 09:33:10,252 global_step: 15,epoch: 0, kl_loss: 0.03447260957553375, reconst_loss: 0.05949574283191136, reward_loss: 0.17341476190616661, actor_loss: 0.6283618211746216, critic_loss: 0.13778826594352722, \n",
      "training actor, critic...\n",
      "actor loss: 0.6461573839187622, critic loss: 0.1370822936296463\n",
      "2024-10-04 09:33:19,274 global_step: 16,epoch: 0, kl_loss: 0.03356226705660929, reconst_loss: 0.059791703233305286, reward_loss: 0.17740327432247982, actor_loss: 0.6461573839187622, critic_loss: 0.1370822936296463, \n",
      "training actor, critic...\n",
      "actor loss: 0.6568235158920288, critic loss: 0.12951476871967316\n",
      "2024-10-04 09:33:28,625 global_step: 17,epoch: 0, kl_loss: 0.03343220805863337, reconst_loss: 0.059351790772408854, reward_loss: 0.21990475842339577, actor_loss: 0.6568235158920288, critic_loss: 0.12951476871967316, \n",
      "training actor, critic...\n",
      "actor loss: 0.6677050590515137, critic loss: 0.12248308956623077\n",
      "2024-10-04 09:33:37,822 global_step: 18,epoch: 0, kl_loss: 0.03260089254614954, reconst_loss: 0.05938931189629496, reward_loss: 0.149152106983226, actor_loss: 0.6677050590515137, critic_loss: 0.12248308956623077, \n",
      "training actor, critic...\n",
      "actor loss: 0.6773684024810791, critic loss: 0.11440915614366531\n",
      "2024-10-04 09:33:47,161 global_step: 19,epoch: 0, kl_loss: 0.032041005666690825, reconst_loss: 0.05901424837659816, reward_loss: 0.18260100665169635, actor_loss: 0.6773684024810791, critic_loss: 0.11440915614366531, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:40<00:00, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:34:27,992 global_step: 0,test_score: 18.13186319161436, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:44<00:00, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:35:12,369 global_step: 20,train_score: -40.57974824680562, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "training actor, critic...\n",
      "actor loss: 0.6808317303657532, critic loss: 0.10232876241207123\n",
      "2024-10-04 09:35:21,754 global_step: 20,epoch: 1, kl_loss: 0.031500272015679856, reconst_loss: 0.05828988574901406, reward_loss: 0.20949900846415181, actor_loss: 0.6808317303657532, critic_loss: 0.10232876241207123, \n",
      "training actor, critic...\n",
      "actor loss: 0.6832895278930664, critic loss: 0.09022171050310135\n",
      "2024-10-04 09:35:30,923 global_step: 21,epoch: 1, kl_loss: 0.030890718843711883, reconst_loss: 0.05832663033993877, reward_loss: 0.20402368033133753, actor_loss: 0.6832895278930664, critic_loss: 0.09022171050310135, \n",
      "training actor, critic...\n",
      "actor loss: 0.6849983334541321, critic loss: 0.07827065885066986\n",
      "2024-10-04 09:35:40,040 global_step: 22,epoch: 1, kl_loss: 0.030243416925017932, reconst_loss: 0.058521484766079455, reward_loss: 0.2298392050956585, actor_loss: 0.6849983334541321, critic_loss: 0.07827065885066986, \n",
      "training actor, critic...\n",
      "actor loss: 0.69305020570755, critic loss: 0.07082199305295944\n",
      "2024-10-04 09:35:49,447 global_step: 23,epoch: 1, kl_loss: 0.029475018795465633, reconst_loss: 0.05737810483088299, reward_loss: 0.17177665739662337, actor_loss: 0.69305020570755, critic_loss: 0.07082199305295944, \n",
      "training actor, critic...\n",
      "actor loss: 0.7060177326202393, critic loss: 0.06573313474655151\n",
      "2024-10-04 09:35:58,550 global_step: 24,epoch: 1, kl_loss: 0.028945070064189483, reconst_loss: 0.05781773363753241, reward_loss: 0.2201579665166459, actor_loss: 0.7060177326202393, critic_loss: 0.06573313474655151, \n",
      "training actor, critic...\n",
      "actor loss: 0.7254979014396667, critic loss: 0.06478552520275116\n",
      "2024-10-04 09:36:09,330 global_step: 25,epoch: 1, kl_loss: 0.028491604203662396, reconst_loss: 0.056334941819006085, reward_loss: 0.18652367599935707, actor_loss: 0.7254979014396667, critic_loss: 0.06478552520275116, \n",
      "training actor, critic...\n",
      "actor loss: 0.7534409761428833, critic loss: 0.06774241477251053\n",
      "2024-10-04 09:36:18,451 global_step: 26,epoch: 1, kl_loss: 0.0278794691156672, reconst_loss: 0.05610533644046102, reward_loss: 0.14281367698247183, actor_loss: 0.7534409761428833, critic_loss: 0.06774241477251053, \n",
      "training actor, critic...\n",
      "actor loss: 0.7829726934432983, critic loss: 0.07172998040914536\n",
      "2024-10-04 09:36:27,642 global_step: 27,epoch: 1, kl_loss: 0.027528390592458298, reconst_loss: 0.05566062413308085, reward_loss: 0.19610684957564334, actor_loss: 0.7829726934432983, critic_loss: 0.07172998040914536, \n",
      "training actor, critic...\n",
      "actor loss: 0.8090523481369019, critic loss: 0.07292228937149048\n",
      "2024-10-04 09:36:37,195 global_step: 28,epoch: 1, kl_loss: 0.026822516302654177, reconst_loss: 0.0549436832721136, reward_loss: 0.22155451996499026, actor_loss: 0.8090523481369019, critic_loss: 0.07292228937149048, \n",
      "training actor, critic...\n",
      "actor loss: 0.8466953635215759, critic loss: 0.08013227581977844\n",
      "2024-10-04 09:36:46,326 global_step: 29,epoch: 1, kl_loss: 0.02656641869083503, reconst_loss: 0.05442032582905828, reward_loss: 0.17126245185618802, actor_loss: 0.8466953635215759, critic_loss: 0.08013227581977844, \n",
      "training actor, critic...\n",
      "actor loss: 0.8769155740737915, critic loss: 0.08414008468389511\n",
      "2024-10-04 09:36:55,564 global_step: 30,epoch: 1, kl_loss: 0.02580182725915267, reconst_loss: 0.0537017889472903, reward_loss: 0.20718936868753207, actor_loss: 0.8769155740737915, critic_loss: 0.08414008468389511, \n",
      "training actor, critic...\n",
      "actor loss: 0.9087628722190857, critic loss: 0.08721675723791122\n",
      "2024-10-04 09:37:04,662 global_step: 31,epoch: 1, kl_loss: 0.02560101400785224, reconst_loss: 0.05275381493325136, reward_loss: 0.22321145954465835, actor_loss: 0.9087628722190857, critic_loss: 0.08721675723791122, \n",
      "training actor, critic...\n",
      "actor loss: 0.9319952726364136, critic loss: 0.08549190312623978\n",
      "2024-10-04 09:37:13,570 global_step: 32,epoch: 1, kl_loss: 0.02506571910724196, reconst_loss: 0.052780618625027795, reward_loss: 0.2088425777881045, actor_loss: 0.9319952726364136, critic_loss: 0.08549190312623978, \n",
      "training actor, critic...\n",
      "actor loss: 0.9607506394386292, critic loss: 0.08632172644138336\n",
      "2024-10-04 09:37:22,738 global_step: 33,epoch: 1, kl_loss: 0.024538298828850443, reconst_loss: 0.05214010581982379, reward_loss: 0.21300601743028633, actor_loss: 0.9607506394386292, critic_loss: 0.08632172644138336, \n",
      "training actor, critic...\n",
      "actor loss: 0.9885032176971436, critic loss: 0.08528892695903778\n",
      "2024-10-04 09:37:32,021 global_step: 34,epoch: 1, kl_loss: 0.024310823335141247, reconst_loss: 0.051614314165650585, reward_loss: 0.20861991254460752, actor_loss: 0.9885032176971436, critic_loss: 0.08528892695903778, \n",
      "training actor, critic...\n",
      "actor loss: 1.0148457288742065, critic loss: 0.0839560404419899\n",
      "2024-10-04 09:37:41,348 global_step: 35,epoch: 1, kl_loss: 0.023675143079623123, reconst_loss: 0.051260524562426975, reward_loss: 0.1794800317694186, actor_loss: 1.0148457288742065, critic_loss: 0.0839560404419899, \n",
      "training actor, critic...\n",
      "actor loss: 1.0501550436019897, critic loss: 0.08688938617706299\n",
      "2024-10-04 09:37:50,438 global_step: 36,epoch: 1, kl_loss: 0.023132928578202063, reconst_loss: 0.050622710996136376, reward_loss: 0.18220541058393308, actor_loss: 1.0501550436019897, critic_loss: 0.08688938617706299, \n",
      "training actor, critic...\n",
      "actor loss: 1.0868265628814697, critic loss: 0.089755117893219\n",
      "2024-10-04 09:37:59,405 global_step: 37,epoch: 1, kl_loss: 0.022951738806726525, reconst_loss: 0.05009314121336353, reward_loss: 0.16077280651815995, actor_loss: 1.0868265628814697, critic_loss: 0.089755117893219, \n",
      "training actor, critic...\n",
      "actor loss: 1.119985580444336, critic loss: 0.09045512974262238\n",
      "2024-10-04 09:38:08,244 global_step: 38,epoch: 1, kl_loss: 0.022497919331095656, reconst_loss: 0.05077203218730129, reward_loss: 0.22269769598805936, actor_loss: 1.119985580444336, critic_loss: 0.09045512974262238, \n",
      "training actor, critic...\n",
      "actor loss: 1.1633254289627075, critic loss: 0.09653989225625992\n",
      "2024-10-04 09:38:17,500 global_step: 39,epoch: 1, kl_loss: 0.021880034594891632, reconst_loss: 0.05017042030789414, reward_loss: 0.13758473331583854, actor_loss: 1.1633254289627075, critic_loss: 0.09653989225625992, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:34<00:00, 11.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:38:52,109 global_step: 40,train_score: -24.205909348286735, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "training actor, critic...\n",
      "actor loss: 1.1982152462005615, critic loss: 0.09734126925468445\n",
      "2024-10-04 09:39:01,163 global_step: 40,epoch: 2, kl_loss: 0.02147642217519484, reconst_loss: 0.04977826203922836, reward_loss: 0.2176303232411797, actor_loss: 1.1982152462005615, critic_loss: 0.09734126925468445, \n",
      "training actor, critic...\n",
      "actor loss: 1.225172996520996, critic loss: 0.09397320449352264\n",
      "2024-10-04 09:39:10,395 global_step: 41,epoch: 2, kl_loss: 0.0212439403261001, reconst_loss: 0.04958156078141563, reward_loss: 0.23272727196560983, actor_loss: 1.225172996520996, critic_loss: 0.09397320449352264, \n",
      "training actor, critic...\n",
      "actor loss: 1.2415794134140015, critic loss: 0.08373169600963593\n",
      "2024-10-04 09:39:19,469 global_step: 42,epoch: 2, kl_loss: 0.020703630289062858, reconst_loss: 0.05006854076470647, reward_loss: 0.23619782843398957, actor_loss: 1.2415794134140015, critic_loss: 0.08373169600963593, \n",
      "training actor, critic...\n",
      "actor loss: 1.2491090297698975, critic loss: 0.07018187642097473\n",
      "2024-10-04 09:39:28,442 global_step: 43,epoch: 2, kl_loss: 0.020363027983040988, reconst_loss: 0.050180397243524084, reward_loss: 0.3087053103990169, actor_loss: 1.2491090297698975, critic_loss: 0.07018187642097473, \n",
      "training actor, critic...\n",
      "actor loss: 1.2566019296646118, critic loss: 0.05837034061551094\n",
      "2024-10-04 09:39:37,553 global_step: 44,epoch: 2, kl_loss: 0.019987130257282024, reconst_loss: 0.04983415226547085, reward_loss: 0.2743836831662576, actor_loss: 1.2566019296646118, critic_loss: 0.05837034061551094, \n",
      "training actor, critic...\n",
      "actor loss: 1.2658333778381348, critic loss: 0.04903212934732437\n",
      "2024-10-04 09:39:47,021 global_step: 45,epoch: 2, kl_loss: 0.019635573461917893, reconst_loss: 0.049004784956270336, reward_loss: 0.21498267583986175, actor_loss: 1.2658333778381348, critic_loss: 0.04903212934732437, \n",
      "training actor, critic...\n",
      "actor loss: 1.2817869186401367, critic loss: 0.044054627418518066\n",
      "2024-10-04 09:39:56,204 global_step: 46,epoch: 2, kl_loss: 0.01926782480155935, reconst_loss: 0.04889291752966083, reward_loss: 0.2103175644724801, actor_loss: 1.2817869186401367, critic_loss: 0.044054627418518066, \n",
      "training actor, critic...\n",
      "actor loss: 1.2991992235183716, critic loss: 0.03950999304652214\n",
      "2024-10-04 09:40:05,277 global_step: 47,epoch: 2, kl_loss: 0.0190567284138227, reconst_loss: 0.04905166591004449, reward_loss: 0.29654365490969953, actor_loss: 1.2991992235183716, critic_loss: 0.03950999304652214, \n",
      "training actor, critic...\n",
      "actor loss: 1.3156530857086182, critic loss: 0.0362226739525795\n",
      "2024-10-04 09:40:14,392 global_step: 48,epoch: 2, kl_loss: 0.01865806321765543, reconst_loss: 0.048040707804718794, reward_loss: 0.266446769912252, actor_loss: 1.3156530857086182, critic_loss: 0.0362226739525795, \n",
      "training actor, critic...\n",
      "actor loss: 1.347800374031067, critic loss: 0.037370871752500534\n",
      "2024-10-04 09:40:23,293 global_step: 49,epoch: 2, kl_loss: 0.01833508996654074, reconst_loss: 0.04784943946466154, reward_loss: 0.21010578939767213, actor_loss: 1.347800374031067, critic_loss: 0.037370871752500534, \n",
      "training actor, critic...\n",
      "actor loss: 1.3851178884506226, critic loss: 0.03902842104434967\n",
      "2024-10-04 09:40:32,344 global_step: 50,epoch: 2, kl_loss: 0.017935287539980242, reconst_loss: 0.048194908289885034, reward_loss: 0.23032690393643415, actor_loss: 1.3851178884506226, critic_loss: 0.03902842104434967, \n",
      "training actor, critic...\n",
      "actor loss: 1.4339923858642578, critic loss: 0.04265087842941284\n",
      "2024-10-04 09:40:41,668 global_step: 51,epoch: 2, kl_loss: 0.01770163417261626, reconst_loss: 0.04774605231929799, reward_loss: 0.18043141114544503, actor_loss: 1.4339923858642578, critic_loss: 0.04265087842941284, \n",
      "training actor, critic...\n",
      "actor loss: 1.4917773008346558, critic loss: 0.05000653490424156\n",
      "2024-10-04 09:40:50,700 global_step: 52,epoch: 2, kl_loss: 0.017446831581467877, reconst_loss: 0.04742608964443207, reward_loss: 0.17479900148107994, actor_loss: 1.4917773008346558, critic_loss: 0.05000653490424156, \n",
      "training actor, critic...\n",
      "actor loss: 1.5527535676956177, critic loss: 0.057378675788640976\n",
      "2024-10-04 09:40:59,785 global_step: 53,epoch: 2, kl_loss: 0.01708675380701161, reconst_loss: 0.04804776593738673, reward_loss: 0.3057973211707205, actor_loss: 1.5527535676956177, critic_loss: 0.057378675788640976, \n",
      "training actor, critic...\n",
      "actor loss: 1.6085706949234009, critic loss: 0.0646292194724083\n",
      "2024-10-04 09:41:08,772 global_step: 54,epoch: 2, kl_loss: 0.0167689829428053, reconst_loss: 0.04712238550490262, reward_loss: 0.21712630474939942, actor_loss: 1.6085706949234009, critic_loss: 0.0646292194724083, \n",
      "training actor, critic...\n",
      "actor loss: 1.6696319580078125, critic loss: 0.07153234630823135\n",
      "2024-10-04 09:41:17,943 global_step: 55,epoch: 2, kl_loss: 0.01656268652509518, reconst_loss: 0.047020998840429346, reward_loss: 0.23564956565292514, actor_loss: 1.6696319580078125, critic_loss: 0.07153234630823135, \n",
      "training actor, critic...\n",
      "actor loss: 1.7268176078796387, critic loss: 0.0739612802863121\n",
      "2024-10-04 09:41:27,020 global_step: 56,epoch: 2, kl_loss: 0.016175261114210804, reconst_loss: 0.04718247215662684, reward_loss: 0.29159983250369526, actor_loss: 1.7268176078796387, critic_loss: 0.0739612802863121, \n",
      "training actor, critic...\n",
      "actor loss: 1.797624945640564, critic loss: 0.08092506974935532\n",
      "2024-10-04 09:41:35,916 global_step: 57,epoch: 2, kl_loss: 0.01605045034702183, reconst_loss: 0.046712766268423626, reward_loss: 0.16392643433729454, actor_loss: 1.797624945640564, critic_loss: 0.08092506974935532, \n",
      "training actor, critic...\n",
      "actor loss: 1.8711297512054443, critic loss: 0.08677870780229568\n",
      "2024-10-04 09:41:44,940 global_step: 58,epoch: 2, kl_loss: 0.015944461984445855, reconst_loss: 0.04648129870088733, reward_loss: 0.23777404710251307, actor_loss: 1.8711297512054443, critic_loss: 0.08677870780229568, \n",
      "training actor, critic...\n",
      "actor loss: 1.9375191926956177, critic loss: 0.0842873826622963\n",
      "2024-10-04 09:41:54,017 global_step: 59,epoch: 2, kl_loss: 0.015776027682978585, reconst_loss: 0.04590848453190862, reward_loss: 0.26857975267387013, actor_loss: 1.9375191926956177, critic_loss: 0.0842873826622963, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:39<00:00, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:42:33,833 global_step: 60,train_score: -49.960653792068975, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n",
      "training actor, critic...\n",
      "actor loss: 2.023080348968506, critic loss: 0.08578900247812271\n",
      "2024-10-04 09:42:43,003 global_step: 60,epoch: 3, kl_loss: 0.015682090938623463, reconst_loss: 0.045122177169031025, reward_loss: 0.1584618837306542, actor_loss: 2.023080348968506, critic_loss: 0.08578900247812271, \n",
      "training actor, critic...\n",
      "actor loss: 2.1225953102111816, critic loss: 0.08995955437421799\n",
      "2024-10-04 09:42:52,271 global_step: 61,epoch: 3, kl_loss: 0.015488251345232129, reconst_loss: 0.0453438046483361, reward_loss: 0.2128380358561265, actor_loss: 2.1225953102111816, critic_loss: 0.08995955437421799, \n",
      "training actor, critic...\n",
      "actor loss: 2.2252440452575684, critic loss: 0.08662063628435135\n",
      "2024-10-04 09:43:02,472 global_step: 62,epoch: 3, kl_loss: 0.015369460423838119, reconst_loss: 0.04524308807995855, reward_loss: 0.222147020554094, actor_loss: 2.2252440452575684, critic_loss: 0.08662063628435135, \n",
      "training actor, critic...\n",
      "actor loss: 2.3502230644226074, critic loss: 0.08714078366756439\n",
      "2024-10-04 09:43:12,103 global_step: 63,epoch: 3, kl_loss: 0.015108757999212461, reconst_loss: 0.04444141313433647, reward_loss: 0.22158263147599538, actor_loss: 2.3502230644226074, critic_loss: 0.08714078366756439, \n",
      "training actor, critic...\n",
      "actor loss: 2.5040454864501953, critic loss: 0.09189917147159576\n",
      "2024-10-04 09:43:21,597 global_step: 64,epoch: 3, kl_loss: 0.014978219317842503, reconst_loss: 0.043942333332129886, reward_loss: 0.1971811526217403, actor_loss: 2.5040454864501953, critic_loss: 0.09189917147159576, \n",
      "training actor, critic...\n",
      "actor loss: 2.6905879974365234, critic loss: 0.0981215387582779\n",
      "2024-10-04 09:43:30,769 global_step: 65,epoch: 3, kl_loss: 0.014730425665573197, reconst_loss: 0.0441939650597621, reward_loss: 0.1978687076800864, actor_loss: 2.6905879974365234, critic_loss: 0.0981215387582779, \n",
      "training actor, critic...\n",
      "actor loss: 2.908830404281616, critic loss: 0.1083955243229866\n",
      "2024-10-04 09:43:40,065 global_step: 66,epoch: 3, kl_loss: 0.014617626973408826, reconst_loss: 0.04358780277626855, reward_loss: 0.16405448044783302, actor_loss: 2.908830404281616, critic_loss: 0.1083955243229866, \n",
      "training actor, critic...\n",
      "actor loss: 3.1770782470703125, critic loss: 0.1225394457578659\n",
      "2024-10-04 09:43:49,415 global_step: 67,epoch: 3, kl_loss: 0.014347733882236846, reconst_loss: 0.04292252089600174, reward_loss: 0.1532120137541954, actor_loss: 3.1770782470703125, critic_loss: 0.1225394457578659, \n",
      "training actor, critic...\n",
      "actor loss: 3.4582390785217285, critic loss: 0.13906872272491455\n",
      "2024-10-04 09:43:58,453 global_step: 68,epoch: 3, kl_loss: 0.014182839979778747, reconst_loss: 0.042783341161450564, reward_loss: 0.20012961165048182, actor_loss: 3.4582390785217285, critic_loss: 0.13906872272491455, \n",
      "training actor, critic...\n",
      "actor loss: 3.741874933242798, critic loss: 0.148569256067276\n",
      "2024-10-04 09:44:07,483 global_step: 69,epoch: 3, kl_loss: 0.013789982097793599, reconst_loss: 0.042736138388210415, reward_loss: 0.2923454281123241, actor_loss: 3.741874933242798, critic_loss: 0.148569256067276, \n",
      "training actor, critic...\n",
      "actor loss: 4.014228820800781, critic loss: 0.1625336855649948\n",
      "2024-10-04 09:44:16,719 global_step: 70,epoch: 3, kl_loss: 0.013238085115480483, reconst_loss: 0.041840169274685333, reward_loss: 0.21985754716609204, actor_loss: 4.014228820800781, critic_loss: 0.1625336855649948, \n",
      "training actor, critic...\n",
      "actor loss: 4.34553861618042, critic loss: 0.18298831582069397\n",
      "2024-10-04 09:44:26,043 global_step: 71,epoch: 3, kl_loss: 0.012691589637792535, reconst_loss: 0.041553127826476584, reward_loss: 0.23196450939249932, actor_loss: 4.34553861618042, critic_loss: 0.18298831582069397, \n",
      "training actor, critic...\n",
      "actor loss: 4.700539588928223, critic loss: 0.20135347545146942\n",
      "2024-10-04 09:44:35,229 global_step: 72,epoch: 3, kl_loss: 0.012080572136886875, reconst_loss: 0.0405531039803612, reward_loss: 0.15347208510324054, actor_loss: 4.700539588928223, critic_loss: 0.20135347545146942, \n",
      "training actor, critic...\n",
      "actor loss: 5.098996639251709, critic loss: 0.22098033130168915\n",
      "2024-10-04 09:44:44,286 global_step: 73,epoch: 3, kl_loss: 0.011510922592513415, reconst_loss: 0.040010107719168374, reward_loss: 0.21622238982449837, actor_loss: 5.098996639251709, critic_loss: 0.22098033130168915, \n",
      "training actor, critic...\n",
      "actor loss: 5.521683216094971, critic loss: 0.26698583364486694\n",
      "2024-10-04 09:44:53,515 global_step: 74,epoch: 3, kl_loss: 0.011103743820318155, reconst_loss: 0.03916358750085441, reward_loss: 0.21392614324101988, actor_loss: 5.521683216094971, critic_loss: 0.26698583364486694, \n",
      "training actor, critic...\n",
      "actor loss: 5.998611927032471, critic loss: 0.30275261402130127\n",
      "2024-10-04 09:45:02,506 global_step: 75,epoch: 3, kl_loss: 0.010611910658071235, reconst_loss: 0.03912036744307498, reward_loss: 0.22245657011125314, actor_loss: 5.998611927032471, critic_loss: 0.30275261402130127, \n",
      "training actor, critic...\n",
      "actor loss: 6.503860950469971, critic loss: 0.3277377486228943\n",
      "2024-10-04 09:45:11,785 global_step: 76,epoch: 3, kl_loss: 0.010131313142423727, reconst_loss: 0.03800469773764513, reward_loss: 0.18749382518878094, actor_loss: 6.503860950469971, critic_loss: 0.3277377486228943, \n",
      "training actor, critic...\n",
      "actor loss: 6.984355926513672, critic loss: 0.38956332206726074\n",
      "2024-10-04 09:45:21,280 global_step: 77,epoch: 3, kl_loss: 0.009666941831914746, reconst_loss: 0.03772317466078973, reward_loss: 0.2202477816169207, actor_loss: 6.984355926513672, critic_loss: 0.38956332206726074, \n",
      "training actor, critic...\n",
      "actor loss: 7.406540393829346, critic loss: 0.41216593980789185\n",
      "2024-10-04 09:45:30,438 global_step: 78,epoch: 3, kl_loss: 0.009218287027003814, reconst_loss: 0.037186916841536154, reward_loss: 0.25972329241660785, actor_loss: 7.406540393829346, critic_loss: 0.41216593980789185, \n",
      "training actor, critic...\n",
      "actor loss: 7.732339382171631, critic loss: 0.4563184678554535\n",
      "2024-10-04 09:45:39,586 global_step: 79,epoch: 3, kl_loss: 0.008933890116762142, reconst_loss: 0.036158036364584555, reward_loss: 0.22925912909570853, actor_loss: 7.732339382171631, critic_loss: 0.4563184678554535, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:38<00:00, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:46:18,080 global_step: 60,test_score: -93.10868201068031, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:40<00:00, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:46:58,323 global_step: 80,train_score: -93.13928868819839, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "training actor, critic...\n",
      "actor loss: 7.959059715270996, critic loss: 0.47426536679267883\n",
      "2024-10-04 09:47:07,375 global_step: 80,epoch: 4, kl_loss: 0.008591430670372685, reconst_loss: 0.035733500001381854, reward_loss: 0.2601017670430319, actor_loss: 7.959059715270996, critic_loss: 0.47426536679267883, \n",
      "training actor, critic...\n",
      "actor loss: 8.092012405395508, critic loss: 0.46709170937538147\n",
      "2024-10-04 09:47:16,415 global_step: 81,epoch: 4, kl_loss: 0.008297206729422418, reconst_loss: 0.035344552400769016, reward_loss: 0.2505299281804081, actor_loss: 8.092012405395508, critic_loss: 0.46709170937538147, \n",
      "training actor, critic...\n",
      "actor loss: 8.143653869628906, critic loss: 0.4743824303150177\n",
      "2024-10-04 09:47:25,461 global_step: 82,epoch: 4, kl_loss: 0.008187980229529192, reconst_loss: 0.03381947146690622, reward_loss: 0.16865815760149638, actor_loss: 8.143653869628906, critic_loss: 0.4743824303150177, \n",
      "training actor, critic...\n",
      "actor loss: 8.14395523071289, critic loss: 0.44295743107795715\n",
      "2024-10-04 09:47:34,522 global_step: 83,epoch: 4, kl_loss: 0.007802175443467437, reconst_loss: 0.03351584897965801, reward_loss: 0.1878255070139635, actor_loss: 8.14395523071289, critic_loss: 0.44295743107795715, \n",
      "training actor, critic...\n",
      "actor loss: 8.084296226501465, critic loss: 0.42397379875183105\n",
      "2024-10-04 09:47:43,770 global_step: 84,epoch: 4, kl_loss: 0.007556523414974918, reconst_loss: 0.03250745113710968, reward_loss: 0.21579059733229936, actor_loss: 8.084296226501465, critic_loss: 0.42397379875183105, \n",
      "training actor, critic...\n",
      "actor loss: 8.00018310546875, critic loss: 0.39373359084129333\n",
      "2024-10-04 09:47:52,787 global_step: 85,epoch: 4, kl_loss: 0.007365635111547855, reconst_loss: 0.03164733984336561, reward_loss: 0.1904744039104339, actor_loss: 8.00018310546875, critic_loss: 0.39373359084129333, \n",
      "training actor, critic...\n",
      "actor loss: 7.879806995391846, critic loss: 0.3702043294906616\n",
      "2024-10-04 09:48:01,829 global_step: 86,epoch: 4, kl_loss: 0.007266582693068349, reconst_loss: 0.030780124839167207, reward_loss: 0.2011817104910139, actor_loss: 7.879806995391846, critic_loss: 0.3702043294906616, \n",
      "training actor, critic...\n",
      "actor loss: 7.710765838623047, critic loss: 0.3473381996154785\n",
      "2024-10-04 09:48:11,047 global_step: 87,epoch: 4, kl_loss: 0.0069699386248783185, reconst_loss: 0.030389109892504557, reward_loss: 0.2342543770198007, actor_loss: 7.710765838623047, critic_loss: 0.3473381996154785, \n",
      "training actor, critic...\n",
      "actor loss: 7.539732456207275, critic loss: 0.32274767756462097\n",
      "2024-10-04 09:48:20,291 global_step: 88,epoch: 4, kl_loss: 0.00682958899712076, reconst_loss: 0.02904571436953788, reward_loss: 0.15365835737760122, actor_loss: 7.539732456207275, critic_loss: 0.32274767756462097, \n",
      "training actor, critic...\n",
      "actor loss: 7.322354793548584, critic loss: 0.3068169057369232\n",
      "2024-10-04 09:48:29,365 global_step: 89,epoch: 4, kl_loss: 0.006826871274305242, reconst_loss: 0.028391235527031277, reward_loss: 0.2386410806318555, actor_loss: 7.322354793548584, critic_loss: 0.3068169057369232, \n",
      "training actor, critic...\n",
      "actor loss: 7.10333251953125, critic loss: 0.276003360748291\n",
      "2024-10-04 09:48:38,234 global_step: 90,epoch: 4, kl_loss: 0.007115454973690972, reconst_loss: 0.026294262091420134, reward_loss: 0.1635268855583379, actor_loss: 7.10333251953125, critic_loss: 0.276003360748291, \n",
      "training actor, critic...\n",
      "actor loss: 6.874484539031982, critic loss: 0.24913722276687622\n",
      "2024-10-04 09:48:47,324 global_step: 91,epoch: 4, kl_loss: 0.006565342894850337, reconst_loss: 0.02655137870080617, reward_loss: 0.179596049378493, actor_loss: 6.874484539031982, critic_loss: 0.24913722276687622, \n",
      "training actor, critic...\n",
      "actor loss: 6.634520053863525, critic loss: 0.22130875289440155\n",
      "2024-10-04 09:48:56,255 global_step: 92,epoch: 4, kl_loss: 0.006325169627991866, reconst_loss: 0.025319665632381732, reward_loss: 0.21191869332569138, actor_loss: 6.634520053863525, critic_loss: 0.22130875289440155, \n",
      "training actor, critic...\n",
      "actor loss: 6.377445697784424, critic loss: 0.1912880837917328\n",
      "2024-10-04 09:49:05,309 global_step: 93,epoch: 4, kl_loss: 0.006213286549461131, reconst_loss: 0.024824173664864228, reward_loss: 0.2359163089303718, actor_loss: 6.377445697784424, critic_loss: 0.1912880837917328, \n",
      "training actor, critic...\n",
      "actor loss: 6.11700963973999, critic loss: 0.17081327736377716\n",
      "2024-10-04 09:49:14,545 global_step: 94,epoch: 4, kl_loss: 0.0064393662828571945, reconst_loss: 0.023351633199015443, reward_loss: 0.2002863374880838, actor_loss: 6.11700963973999, critic_loss: 0.17081327736377716, \n",
      "training actor, critic...\n",
      "actor loss: 5.873579025268555, critic loss: 0.15390866994857788\n",
      "2024-10-04 09:49:23,673 global_step: 95,epoch: 4, kl_loss: 0.006202261761895248, reconst_loss: 0.02358242850370553, reward_loss: 0.22662334957597208, actor_loss: 5.873579025268555, critic_loss: 0.15390866994857788, \n",
      "training actor, critic...\n",
      "actor loss: 5.648936748504639, critic loss: 0.14144548773765564\n",
      "2024-10-04 09:49:32,693 global_step: 96,epoch: 4, kl_loss: 0.005869781460651025, reconst_loss: 0.02238640584507767, reward_loss: 0.22113315571023492, actor_loss: 5.648936748504639, critic_loss: 0.14144548773765564, \n",
      "training actor, critic...\n",
      "actor loss: 5.443354606628418, critic loss: 0.1251763552427292\n",
      "2024-10-04 09:49:41,675 global_step: 97,epoch: 4, kl_loss: 0.005619407759751289, reconst_loss: 0.021754914324502557, reward_loss: 0.20181814456662658, actor_loss: 5.443354606628418, critic_loss: 0.1251763552427292, \n",
      "training actor, critic...\n",
      "actor loss: 5.2700347900390625, critic loss: 0.11678317934274673\n",
      "2024-10-04 09:49:50,574 global_step: 98,epoch: 4, kl_loss: 0.005712816524984581, reconst_loss: 0.02111925606672861, reward_loss: 0.1789721621590077, actor_loss: 5.2700347900390625, critic_loss: 0.11678317934274673, \n",
      "training actor, critic...\n",
      "actor loss: 5.16819429397583, critic loss: 0.11602282524108887\n",
      "2024-10-04 09:49:59,810 global_step: 99,epoch: 4, kl_loss: 0.005731681760932718, reconst_loss: 0.020477289714071215, reward_loss: 0.11825556534684586, actor_loss: 5.16819429397583, critic_loss: 0.11602282524108887, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:34<00:00, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:50:34,323 global_step: 100,train_score: -93.12822851680771, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000\n",
      "training actor, critic...\n",
      "actor loss: 5.077959060668945, critic loss: 0.11478555202484131\n",
      "2024-10-04 09:50:44,258 global_step: 100,epoch: 5, kl_loss: 0.005406432015327167, reconst_loss: 0.020356987660028497, reward_loss: 0.23172599372539518, actor_loss: 5.077959060668945, critic_loss: 0.11478555202484131, \n",
      "training actor, critic...\n",
      "actor loss: 5.0248894691467285, critic loss: 0.10869759321212769\n",
      "2024-10-04 09:50:53,646 global_step: 101,epoch: 5, kl_loss: 0.005256889117121392, reconst_loss: 0.019909548744255184, reward_loss: 0.20257097774669908, actor_loss: 5.0248894691467285, critic_loss: 0.10869759321212769, \n",
      "training actor, critic...\n",
      "actor loss: 4.991273880004883, critic loss: 0.09975573420524597\n",
      "2024-10-04 09:51:02,777 global_step: 102,epoch: 5, kl_loss: 0.005148085546964894, reconst_loss: 0.0196505890284874, reward_loss: 0.20070641073493325, actor_loss: 4.991273880004883, critic_loss: 0.09975573420524597, \n",
      "training actor, critic...\n",
      "actor loss: 4.9755682945251465, critic loss: 0.09397738426923752\n",
      "2024-10-04 09:51:11,837 global_step: 103,epoch: 5, kl_loss: 0.0052346033946972115, reconst_loss: 0.019071768893271078, reward_loss: 0.20960537992341785, actor_loss: 4.9755682945251465, critic_loss: 0.09397738426923752, \n",
      "training actor, critic...\n",
      "actor loss: 5.0078582763671875, critic loss: 0.09514760226011276\n",
      "2024-10-04 09:51:21,080 global_step: 104,epoch: 5, kl_loss: 0.004990185444642391, reconst_loss: 0.01833440332996602, reward_loss: 0.12129753619451455, actor_loss: 5.0078582763671875, critic_loss: 0.09514760226011276, \n",
      "training actor, critic...\n",
      "actor loss: 5.0536394119262695, critic loss: 0.09709520637989044\n",
      "2024-10-04 09:51:30,502 global_step: 105,epoch: 5, kl_loss: 0.004859800958929926, reconst_loss: 0.0185839159376159, reward_loss: 0.19667657986948534, actor_loss: 5.0536394119262695, critic_loss: 0.09709520637989044, \n",
      "training actor, critic...\n",
      "actor loss: 5.126323699951172, critic loss: 0.09917016327381134\n",
      "2024-10-04 09:51:39,680 global_step: 106,epoch: 5, kl_loss: 0.004771405370069706, reconst_loss: 0.017086605978559474, reward_loss: 0.16101073804406488, actor_loss: 5.126323699951172, critic_loss: 0.09917016327381134, \n",
      "training actor, critic...\n",
      "actor loss: 5.229383945465088, critic loss: 0.10955070704221725\n",
      "2024-10-04 09:51:48,966 global_step: 107,epoch: 5, kl_loss: 0.004719104076146471, reconst_loss: 0.017225569000049512, reward_loss: 0.1426887735486867, actor_loss: 5.229383945465088, critic_loss: 0.10955070704221725, \n",
      "training actor, critic...\n",
      "actor loss: 5.325777530670166, critic loss: 0.10764060169458389\n",
      "2024-10-04 09:51:58,174 global_step: 108,epoch: 5, kl_loss: 0.004620633867322182, reconst_loss: 0.016704050405901307, reward_loss: 0.22899128025996365, actor_loss: 5.325777530670166, critic_loss: 0.10764060169458389, \n",
      "training actor, critic...\n",
      "actor loss: 5.4660868644714355, critic loss: 0.11181551218032837\n",
      "2024-10-04 09:52:07,118 global_step: 109,epoch: 5, kl_loss: 0.004453358401981544, reconst_loss: 0.016704174537895893, reward_loss: 0.11195248277971939, actor_loss: 5.4660868644714355, critic_loss: 0.11181551218032837, \n",
      "training actor, critic...\n",
      "actor loss: 5.629334449768066, critic loss: 0.11571250110864639\n",
      "2024-10-04 09:52:16,131 global_step: 110,epoch: 5, kl_loss: 0.004443134917706555, reconst_loss: 0.01664736819434531, reward_loss: 0.18398397881775258, actor_loss: 5.629334449768066, critic_loss: 0.11571250110864639, \n",
      "training actor, critic...\n",
      "actor loss: 5.814036846160889, critic loss: 0.1225043460726738\n",
      "2024-10-04 09:52:25,474 global_step: 111,epoch: 5, kl_loss: 0.00432394340406267, reconst_loss: 0.01650392611948203, reward_loss: 0.1523776705215248, actor_loss: 5.814036846160889, critic_loss: 0.1225043460726738, \n",
      "training actor, critic...\n",
      "actor loss: 6.007856369018555, critic loss: 0.12486492097377777\n",
      "2024-10-04 09:52:34,533 global_step: 112,epoch: 5, kl_loss: 0.004237275532617861, reconst_loss: 0.015425912940836683, reward_loss: 0.1587347841978415, actor_loss: 6.007856369018555, critic_loss: 0.12486492097377777, \n",
      "training actor, critic...\n",
      "actor loss: 6.18588924407959, critic loss: 0.1297922134399414\n",
      "2024-10-04 09:52:43,523 global_step: 113,epoch: 5, kl_loss: 0.004148464402830114, reconst_loss: 0.015910845477970278, reward_loss: 0.19858389333774318, actor_loss: 6.18588924407959, critic_loss: 0.1297922134399414, \n",
      "training actor, critic...\n",
      "actor loss: 6.346091270446777, critic loss: 0.14073701202869415\n",
      "2024-10-04 09:52:52,507 global_step: 114,epoch: 5, kl_loss: 0.004067590764286567, reconst_loss: 0.01629257091910255, reward_loss: 0.2033111019349866, actor_loss: 6.346091270446777, critic_loss: 0.14073701202869415, \n",
      "training actor, critic...\n",
      "actor loss: 6.48581600189209, critic loss: 0.14517129957675934\n",
      "2024-10-04 09:53:01,533 global_step: 115,epoch: 5, kl_loss: 0.004046622411899117, reconst_loss: 0.015544681600770173, reward_loss: 0.15798121705005058, actor_loss: 6.48581600189209, critic_loss: 0.14517129957675934, \n",
      "training actor, critic...\n",
      "actor loss: 6.556843280792236, critic loss: 0.15355181694030762\n",
      "2024-10-04 09:53:10,927 global_step: 116,epoch: 5, kl_loss: 0.004032998198491274, reconst_loss: 0.01549414974846402, reward_loss: 0.24844205162811037, actor_loss: 6.556843280792236, critic_loss: 0.15355181694030762, \n",
      "training actor, critic...\n",
      "actor loss: 6.586703300476074, critic loss: 0.15300165116786957\n",
      "2024-10-04 09:53:19,989 global_step: 117,epoch: 5, kl_loss: 0.0038809917430032274, reconst_loss: 0.014766706286796502, reward_loss: 0.14867764409650497, actor_loss: 6.586703300476074, critic_loss: 0.15300165116786957, \n",
      "training actor, critic...\n",
      "actor loss: 6.5638957023620605, critic loss: 0.1512216478586197\n",
      "2024-10-04 09:53:29,078 global_step: 118,epoch: 5, kl_loss: 0.0038233749872567703, reconst_loss: 0.015120321010448495, reward_loss: 0.1841043474114671, actor_loss: 6.5638957023620605, critic_loss: 0.1512216478586197, \n",
      "training actor, critic...\n",
      "actor loss: 6.504764080047607, critic loss: 0.1403355747461319\n",
      "2024-10-04 09:53:38,191 global_step: 119,epoch: 5, kl_loss: 0.003752004637915109, reconst_loss: 0.014356450481834461, reward_loss: 0.1779576753959896, actor_loss: 6.504764080047607, critic_loss: 0.1403355747461319, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:39<00:00, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:54:18,077 global_step: 120,train_score: -93.47998800130453, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26000\n",
      "training actor, critic...\n",
      "actor loss: 6.44756555557251, critic loss: 0.1339159458875656\n",
      "2024-10-04 09:54:32,309 global_step: 120,epoch: 6, kl_loss: 0.003792242085257051, reconst_loss: 0.01373792000647102, reward_loss: 0.11011664845923684, actor_loss: 6.44756555557251, critic_loss: 0.1339159458875656, \n",
      "training actor, critic...\n",
      "actor loss: 6.379302024841309, critic loss: 0.13147017359733582\n",
      "2024-10-04 09:54:41,730 global_step: 121,epoch: 6, kl_loss: 0.0037494328072560684, reconst_loss: 0.01451866418047219, reward_loss: 0.21663206130769863, actor_loss: 6.379302024841309, critic_loss: 0.13147017359733582, \n",
      "training actor, critic...\n",
      "actor loss: 6.33648681640625, critic loss: 0.13331502676010132\n",
      "2024-10-04 09:54:51,217 global_step: 122,epoch: 6, kl_loss: 0.003667163916825488, reconst_loss: 0.013946238563072925, reward_loss: 0.14883846606897685, actor_loss: 6.33648681640625, critic_loss: 0.13331502676010132, \n",
      "training actor, critic...\n",
      "actor loss: 6.333540916442871, critic loss: 0.13383056223392487\n",
      "2024-10-04 09:55:00,338 global_step: 123,epoch: 6, kl_loss: 0.003684883592745327, reconst_loss: 0.012789146176406316, reward_loss: 0.12018362286605169, actor_loss: 6.333540916442871, critic_loss: 0.13383056223392487, \n",
      "training actor, critic...\n",
      "actor loss: 6.377042293548584, critic loss: 0.13654756546020508\n",
      "2024-10-04 09:55:09,616 global_step: 124,epoch: 6, kl_loss: 0.0036981671725456813, reconst_loss: 0.012179628432709344, reward_loss: 0.1123178466508279, actor_loss: 6.377042293548584, critic_loss: 0.13654756546020508, \n",
      "training actor, critic...\n",
      "actor loss: 6.440337181091309, critic loss: 0.13504526019096375\n",
      "2024-10-04 09:55:18,700 global_step: 125,epoch: 6, kl_loss: 0.003657598668538338, reconst_loss: 0.013793078156150117, reward_loss: 0.18149861664516015, actor_loss: 6.440337181091309, critic_loss: 0.13504526019096375, \n",
      "training actor, critic...\n",
      "actor loss: 6.519416332244873, critic loss: 0.12984277307987213\n",
      "2024-10-04 09:55:28,109 global_step: 126,epoch: 6, kl_loss: 0.0035897910509410562, reconst_loss: 0.013000279760026202, reward_loss: 0.15089611962499402, actor_loss: 6.519416332244873, critic_loss: 0.12984277307987213, \n",
      "training actor, critic...\n",
      "actor loss: 6.601439476013184, critic loss: 0.13232646882534027\n",
      "2024-10-04 09:55:37,376 global_step: 127,epoch: 6, kl_loss: 0.0036606992599649392, reconst_loss: 0.012614618948831851, reward_loss: 0.13891807972567574, actor_loss: 6.601439476013184, critic_loss: 0.13232646882534027, \n",
      "training actor, critic...\n",
      "actor loss: 6.648143291473389, critic loss: 0.13592684268951416\n",
      "2024-10-04 09:55:46,508 global_step: 128,epoch: 6, kl_loss: 0.0035819517785911355, reconst_loss: 0.013813793317091708, reward_loss: 0.229140220815791, actor_loss: 6.648143291473389, critic_loss: 0.13592684268951416, \n",
      "training actor, critic...\n",
      "actor loss: 6.650534629821777, critic loss: 0.1405268907546997\n",
      "2024-10-04 09:55:55,550 global_step: 129,epoch: 6, kl_loss: 0.003567811990232796, reconst_loss: 0.01329840582852461, reward_loss: 0.18180857692864172, actor_loss: 6.650534629821777, critic_loss: 0.1405268907546997, \n",
      "training actor, critic...\n",
      "actor loss: 6.578177452087402, critic loss: 0.14547327160835266\n",
      "2024-10-04 09:56:04,505 global_step: 130,epoch: 6, kl_loss: 0.003562028545943298, reconst_loss: 0.012419362970608838, reward_loss: 0.2126307372592998, actor_loss: 6.578177452087402, critic_loss: 0.14547327160835266, \n",
      "training actor, critic...\n",
      "actor loss: 6.46856164932251, critic loss: 0.1314229518175125\n",
      "2024-10-04 09:56:13,611 global_step: 131,epoch: 6, kl_loss: 0.003506621956464131, reconst_loss: 0.012107599792735917, reward_loss: 0.13885678329067874, actor_loss: 6.46856164932251, critic_loss: 0.1314229518175125, \n",
      "training actor, critic...\n",
      "actor loss: 6.326176166534424, critic loss: 0.11630258709192276\n",
      "2024-10-04 09:56:22,814 global_step: 132,epoch: 6, kl_loss: 0.0035037487027786522, reconst_loss: 0.012146784771918034, reward_loss: 0.15382206749304064, actor_loss: 6.326176166534424, critic_loss: 0.11630258709192276, \n",
      "training actor, critic...\n",
      "actor loss: 6.176413059234619, critic loss: 0.10403047502040863\n",
      "2024-10-04 09:56:31,886 global_step: 133,epoch: 6, kl_loss: 0.0035378865764609407, reconst_loss: 0.012417221707957131, reward_loss: 0.15920983426443927, actor_loss: 6.176413059234619, critic_loss: 0.10403047502040863, \n",
      "training actor, critic...\n",
      "actor loss: 6.037333965301514, critic loss: 0.1033574789762497\n",
      "2024-10-04 09:56:40,911 global_step: 134,epoch: 6, kl_loss: 0.003472687201384379, reconst_loss: 0.011725312916143817, reward_loss: 0.1529619756596619, actor_loss: 6.037333965301514, critic_loss: 0.1033574789762497, \n",
      "training actor, critic...\n",
      "actor loss: 5.930046081542969, critic loss: 0.10238581150770187\n",
      "2024-10-04 09:56:49,879 global_step: 135,epoch: 6, kl_loss: 0.003509379077550708, reconst_loss: 0.012394467254682464, reward_loss: 0.14333978133532693, actor_loss: 5.930046081542969, critic_loss: 0.10238581150770187, \n",
      "training actor, critic...\n",
      "actor loss: 5.863026142120361, critic loss: 0.10385656356811523\n",
      "2024-10-04 09:56:59,041 global_step: 136,epoch: 6, kl_loss: 0.003406749313640199, reconst_loss: 0.012517648007796735, reward_loss: 0.18899197143512037, actor_loss: 5.863026142120361, critic_loss: 0.10385656356811523, \n",
      "training actor, critic...\n",
      "actor loss: 5.846026420593262, critic loss: 0.10457716882228851\n",
      "2024-10-04 09:57:08,387 global_step: 137,epoch: 6, kl_loss: 0.0034297061252540778, reconst_loss: 0.011265945411762414, reward_loss: 0.13189220140635854, actor_loss: 5.846026420593262, critic_loss: 0.10457716882228851, \n",
      "training actor, critic...\n",
      "actor loss: 5.880803108215332, critic loss: 0.10476977378129959\n",
      "2024-10-04 09:57:17,469 global_step: 138,epoch: 6, kl_loss: 0.00339785544439314, reconst_loss: 0.011781438919050353, reward_loss: 0.12055743669815437, actor_loss: 5.880803108215332, critic_loss: 0.10476977378129959, \n",
      "training actor, critic...\n",
      "actor loss: 5.960488319396973, critic loss: 0.10650331526994705\n",
      "2024-10-04 09:57:26,409 global_step: 139,epoch: 6, kl_loss: 0.003369863815035443, reconst_loss: 0.0118302780260541, reward_loss: 0.12047571454753112, actor_loss: 5.960488319396973, critic_loss: 0.10650331526994705, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:41<00:00, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:58:07,595 global_step: 120,test_score: -93.44236185523967, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:43<00:00, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 09:58:51,257 global_step: 140,train_score: -92.21939763280393, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n",
      "training actor, critic...\n",
      "actor loss: 6.083479881286621, critic loss: 0.10632853209972382\n",
      "2024-10-04 09:59:02,853 global_step: 140,epoch: 7, kl_loss: 0.0033180087267858337, reconst_loss: 0.01145254514579262, reward_loss: 0.11418336793918124, actor_loss: 6.083479881286621, critic_loss: 0.10632853209972382, \n",
      "training actor, critic...\n",
      "actor loss: 6.22578239440918, critic loss: 0.10489938408136368\n",
      "2024-10-04 09:59:12,396 global_step: 141,epoch: 7, kl_loss: 0.0033264091494968353, reconst_loss: 0.011483695757176195, reward_loss: 0.1385133317873661, actor_loss: 6.22578239440918, critic_loss: 0.10489938408136368, \n",
      "training actor, critic...\n",
      "actor loss: 6.37975549697876, critic loss: 0.10548047721385956\n",
      "2024-10-04 09:59:21,531 global_step: 142,epoch: 7, kl_loss: 0.0032554058267791966, reconst_loss: 0.011331113644552474, reward_loss: 0.19484436707880007, actor_loss: 6.37975549697876, critic_loss: 0.10548047721385956, \n",
      "training actor, critic...\n",
      "actor loss: 6.535158634185791, critic loss: 0.1091780811548233\n",
      "2024-10-04 09:59:30,823 global_step: 143,epoch: 7, kl_loss: 0.0032420083737875124, reconst_loss: 0.011855559366546115, reward_loss: 0.15176753397099674, actor_loss: 6.535158634185791, critic_loss: 0.1091780811548233, \n",
      "training actor, critic...\n",
      "actor loss: 6.676253318786621, critic loss: 0.11355079710483551\n",
      "2024-10-04 09:59:39,789 global_step: 144,epoch: 7, kl_loss: 0.00315405055405382, reconst_loss: 0.01198753079741585, reward_loss: 0.1714817354674166, actor_loss: 6.676253318786621, critic_loss: 0.11355079710483551, \n",
      "training actor, critic...\n",
      "actor loss: 6.777731895446777, critic loss: 0.1215943694114685\n",
      "2024-10-04 09:59:49,130 global_step: 145,epoch: 7, kl_loss: 0.00314847582818142, reconst_loss: 0.012026504784518359, reward_loss: 0.20479141123953978, actor_loss: 6.777731895446777, critic_loss: 0.1215943694114685, \n",
      "training actor, critic...\n",
      "actor loss: 6.841712474822998, critic loss: 0.12539279460906982\n",
      "2024-10-04 09:59:58,014 global_step: 146,epoch: 7, kl_loss: 0.0031226805971973403, reconst_loss: 0.010351739234614129, reward_loss: 0.14505342110677868, actor_loss: 6.841712474822998, critic_loss: 0.12539279460906982, \n",
      "training actor, critic...\n",
      "actor loss: 6.863189697265625, critic loss: 0.12367051839828491\n",
      "2024-10-04 10:00:07,207 global_step: 147,epoch: 7, kl_loss: 0.0030403459867538543, reconst_loss: 0.011619065184982456, reward_loss: 0.11240407938555795, actor_loss: 6.863189697265625, critic_loss: 0.12367051839828491, \n",
      "training actor, critic...\n",
      "actor loss: 6.842329978942871, critic loss: 0.12077192217111588\n",
      "2024-10-04 10:00:16,533 global_step: 148,epoch: 7, kl_loss: 0.0030137520967697612, reconst_loss: 0.011143154179563328, reward_loss: 0.18265582752480572, actor_loss: 6.842329978942871, critic_loss: 0.12077192217111588, \n",
      "training actor, critic...\n",
      "actor loss: 6.794331073760986, critic loss: 0.11516718566417694\n",
      "2024-10-04 10:00:25,429 global_step: 149,epoch: 7, kl_loss: 0.0030274254540741748, reconst_loss: 0.011566001693813168, reward_loss: 0.16471385313150455, actor_loss: 6.794331073760986, critic_loss: 0.11516718566417694, \n",
      "training actor, critic...\n",
      "actor loss: 6.731168270111084, critic loss: 0.11107824742794037\n",
      "2024-10-04 10:00:34,604 global_step: 150,epoch: 7, kl_loss: 0.0029328029236889313, reconst_loss: 0.01047622918018273, reward_loss: 0.1317378063163511, actor_loss: 6.731168270111084, critic_loss: 0.11107824742794037, \n",
      "training actor, critic...\n",
      "actor loss: 6.6676926612854, critic loss: 0.11101623624563217\n",
      "2024-10-04 10:00:43,517 global_step: 151,epoch: 7, kl_loss: 0.0029452511118915007, reconst_loss: 0.011289971994654256, reward_loss: 0.16610582639007088, actor_loss: 6.6676926612854, critic_loss: 0.11101623624563217, \n",
      "training actor, critic...\n",
      "actor loss: 6.612560749053955, critic loss: 0.10776674002408981\n",
      "2024-10-04 10:00:52,400 global_step: 152,epoch: 7, kl_loss: 0.0029049494555600137, reconst_loss: 0.010713790980528812, reward_loss: 0.12853897626901387, actor_loss: 6.612560749053955, critic_loss: 0.10776674002408981, \n",
      "training actor, critic...\n",
      "actor loss: 6.578420162200928, critic loss: 0.10761643201112747\n",
      "2024-10-04 10:01:01,399 global_step: 153,epoch: 7, kl_loss: 0.0028697634258364538, reconst_loss: 0.010305989514656213, reward_loss: 0.15194965806333538, actor_loss: 6.578420162200928, critic_loss: 0.10761643201112747, \n",
      "training actor, critic...\n",
      "actor loss: 6.561268329620361, critic loss: 0.10594900697469711\n",
      "2024-10-04 10:01:10,467 global_step: 154,epoch: 7, kl_loss: 0.0027797270723029363, reconst_loss: 0.009859127581727748, reward_loss: 0.14724024350051673, actor_loss: 6.561268329620361, critic_loss: 0.10594900697469711, \n",
      "training actor, critic...\n",
      "actor loss: 6.563234806060791, critic loss: 0.10549721121788025\n",
      "2024-10-04 10:01:19,466 global_step: 155,epoch: 7, kl_loss: 0.002887737623662973, reconst_loss: 0.010082998769167734, reward_loss: 0.14625156453896163, actor_loss: 6.563234806060791, critic_loss: 0.10549721121788025, \n",
      "training actor, critic...\n",
      "actor loss: 6.583637714385986, critic loss: 0.10348547250032425\n",
      "2024-10-04 10:01:28,587 global_step: 156,epoch: 7, kl_loss: 0.0027678002631861946, reconst_loss: 0.009807368075209004, reward_loss: 0.1728855745714842, actor_loss: 6.583637714385986, critic_loss: 0.10348547250032425, \n",
      "training actor, critic...\n",
      "actor loss: 6.607952117919922, critic loss: 0.10241524130105972\n",
      "2024-10-04 10:01:37,331 global_step: 157,epoch: 7, kl_loss: 0.0027216920161106605, reconst_loss: 0.010253630293419167, reward_loss: 0.18808070507033595, actor_loss: 6.607952117919922, critic_loss: 0.10241524130105972, \n",
      "training actor, critic...\n",
      "actor loss: 6.626875400543213, critic loss: 0.10292404145002365\n",
      "2024-10-04 10:01:46,552 global_step: 158,epoch: 7, kl_loss: 0.002770498271423335, reconst_loss: 0.010862607603930697, reward_loss: 0.17524048523758823, actor_loss: 6.626875400543213, critic_loss: 0.10292404145002365, \n",
      "training actor, critic...\n",
      "actor loss: 6.639311790466309, critic loss: 0.1034633070230484\n",
      "2024-10-04 10:01:55,549 global_step: 159,epoch: 7, kl_loss: 0.002715276529280735, reconst_loss: 0.01086593618882554, reward_loss: 0.12829600889425802, actor_loss: 6.639311790466309, critic_loss: 0.1034633070230484, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:40<00:00, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:02:36,296 global_step: 160,train_score: -93.35956441219416, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "training actor, critic...\n",
      "actor loss: 6.645365238189697, critic loss: 0.10383959114551544\n",
      "2024-10-04 10:02:49,193 global_step: 160,epoch: 8, kl_loss: 0.0027135148577924284, reconst_loss: 0.009425457319890966, reward_loss: 0.10923001277070417, actor_loss: 6.645365238189697, critic_loss: 0.10383959114551544, \n",
      "training actor, critic...\n",
      "actor loss: 6.645007610321045, critic loss: 0.10300573706626892\n",
      "2024-10-04 10:02:58,322 global_step: 161,epoch: 8, kl_loss: 0.002754152826109559, reconst_loss: 0.009591666050255299, reward_loss: 0.10827057148871601, actor_loss: 6.645007610321045, critic_loss: 0.10300573706626892, \n",
      "training actor, critic...\n",
      "actor loss: 6.639404773712158, critic loss: 0.10034840553998947\n",
      "2024-10-04 10:03:07,521 global_step: 162,epoch: 8, kl_loss: 0.0026556682269259983, reconst_loss: 0.010345236645365248, reward_loss: 0.14170679977942943, actor_loss: 6.639404773712158, critic_loss: 0.10034840553998947, \n",
      "training actor, critic...\n",
      "actor loss: 6.63866662979126, critic loss: 0.1024276539683342\n",
      "2024-10-04 10:03:16,840 global_step: 163,epoch: 8, kl_loss: 0.002636335386267426, reconst_loss: 0.00977926703207955, reward_loss: 0.14272727653840367, actor_loss: 6.63866662979126, critic_loss: 0.1024276539683342, \n",
      "training actor, critic...\n",
      "actor loss: 6.653619766235352, critic loss: 0.10273518413305283\n",
      "2024-10-04 10:03:25,923 global_step: 164,epoch: 8, kl_loss: 0.00266808875461052, reconst_loss: 0.009825466979979252, reward_loss: 0.11343088168270733, actor_loss: 6.653619766235352, critic_loss: 0.10273518413305283, \n",
      "training actor, critic...\n",
      "actor loss: 6.692354679107666, critic loss: 0.10400282591581345\n",
      "2024-10-04 10:03:35,178 global_step: 165,epoch: 8, kl_loss: 0.002581211386666614, reconst_loss: 0.00954294053609578, reward_loss: 0.1484102663056621, actor_loss: 6.692354679107666, critic_loss: 0.10400282591581345, \n",
      "training actor, critic...\n",
      "actor loss: 6.752374172210693, critic loss: 0.1068028137087822\n",
      "2024-10-04 10:03:44,130 global_step: 166,epoch: 8, kl_loss: 0.0025510390845070383, reconst_loss: 0.009851715394428797, reward_loss: 0.14526260376561015, actor_loss: 6.752374172210693, critic_loss: 0.1068028137087822, \n",
      "training actor, critic...\n",
      "actor loss: 6.838035583496094, critic loss: 0.10846061259508133\n",
      "2024-10-04 10:03:53,145 global_step: 167,epoch: 8, kl_loss: 0.0025541056493981456, reconst_loss: 0.009696464339385227, reward_loss: 0.12601300921143813, actor_loss: 6.838035583496094, critic_loss: 0.10846061259508133, \n",
      "training actor, critic...\n",
      "actor loss: 6.94890832901001, critic loss: 0.1101824939250946\n",
      "2024-10-04 10:04:02,135 global_step: 168,epoch: 8, kl_loss: 0.0025427655046045476, reconst_loss: 0.010159469247624581, reward_loss: 0.12490178845532961, actor_loss: 6.94890832901001, critic_loss: 0.1101824939250946, \n",
      "training actor, critic...\n",
      "actor loss: 7.084758281707764, critic loss: 0.11325719952583313\n",
      "2024-10-04 10:04:11,370 global_step: 169,epoch: 8, kl_loss: 0.0024737822704435307, reconst_loss: 0.009458039697183639, reward_loss: 0.10022009102442321, actor_loss: 7.084758281707764, critic_loss: 0.11325719952583313, \n",
      "training actor, critic...\n",
      "actor loss: 7.2284674644470215, critic loss: 0.11952309310436249\n",
      "2024-10-04 10:04:20,455 global_step: 170,epoch: 8, kl_loss: 0.0025267173899622746, reconst_loss: 0.009885638134972173, reward_loss: 0.14300902575439756, actor_loss: 7.2284674644470215, critic_loss: 0.11952309310436249, \n",
      "training actor, critic...\n",
      "actor loss: 7.379425525665283, critic loss: 0.12139614671468735\n",
      "2024-10-04 10:04:29,303 global_step: 171,epoch: 8, kl_loss: 0.0024803604322428605, reconst_loss: 0.008315227783228062, reward_loss: 0.08546888731581596, actor_loss: 7.379425525665283, critic_loss: 0.12139614671468735, \n",
      "training actor, critic...\n",
      "actor loss: 7.518362045288086, critic loss: 0.130622997879982\n",
      "2024-10-04 10:04:38,402 global_step: 172,epoch: 8, kl_loss: 0.002495518455528939, reconst_loss: 0.009195039542962094, reward_loss: 0.1457703249892505, actor_loss: 7.518362045288086, critic_loss: 0.130622997879982, \n",
      "training actor, critic...\n",
      "actor loss: 7.635158538818359, critic loss: 0.1311732530593872\n",
      "2024-10-04 10:04:47,304 global_step: 173,epoch: 8, kl_loss: 0.002492353288048156, reconst_loss: 0.009451022941847237, reward_loss: 0.12422378682792756, actor_loss: 7.635158538818359, critic_loss: 0.1311732530593872, \n",
      "training actor, critic...\n",
      "actor loss: 7.701560020446777, critic loss: 0.13556723296642303\n",
      "2024-10-04 10:04:56,281 global_step: 174,epoch: 8, kl_loss: 0.0024789163453162325, reconst_loss: 0.010203265071827538, reward_loss: 0.19753046782345188, actor_loss: 7.701560020446777, critic_loss: 0.13556723296642303, \n",
      "training actor, critic...\n",
      "actor loss: 7.709156513214111, critic loss: 0.13451659679412842\n",
      "2024-10-04 10:05:05,379 global_step: 175,epoch: 8, kl_loss: 0.0024269523921099548, reconst_loss: 0.009582802083115188, reward_loss: 0.1485964294988662, actor_loss: 7.709156513214111, critic_loss: 0.13451659679412842, \n",
      "training actor, critic...\n",
      "actor loss: 7.644895076751709, critic loss: 0.13683392107486725\n",
      "2024-10-04 10:05:14,447 global_step: 176,epoch: 8, kl_loss: 0.002460827015112249, reconst_loss: 0.010023756903045031, reward_loss: 0.19143107641317256, actor_loss: 7.644895076751709, critic_loss: 0.13683392107486725, \n",
      "training actor, critic...\n",
      "actor loss: 7.510861873626709, critic loss: 0.13351191580295563\n",
      "2024-10-04 10:05:23,349 global_step: 177,epoch: 8, kl_loss: 0.002450934385557716, reconst_loss: 0.00933636061619131, reward_loss: 0.15763170360254922, actor_loss: 7.510861873626709, critic_loss: 0.13351191580295563, \n",
      "training actor, critic...\n",
      "actor loss: 7.320231914520264, critic loss: 0.1233549565076828\n",
      "2024-10-04 10:05:32,264 global_step: 178,epoch: 8, kl_loss: 0.002422874381205029, reconst_loss: 0.009699927101253855, reward_loss: 0.18581581042784892, actor_loss: 7.320231914520264, critic_loss: 0.1233549565076828, \n",
      "training actor, critic...\n",
      "actor loss: 7.110517501831055, critic loss: 0.10912251472473145\n",
      "2024-10-04 10:05:41,500 global_step: 179,epoch: 8, kl_loss: 0.002377030497882515, reconst_loss: 0.007963252890550969, reward_loss: 0.05724956676344938, actor_loss: 7.110517501831055, critic_loss: 0.10912251472473145, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:35<00:00, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:06:17,089 global_step: 180,train_score: -92.81039781728327, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35000\n",
      "training actor, critic...\n",
      "actor loss: 6.888499736785889, critic loss: 0.09816811233758926\n",
      "2024-10-04 10:06:28,200 global_step: 180,epoch: 9, kl_loss: 0.0023894357810994343, reconst_loss: 0.008736148353057856, reward_loss: 0.1419854277022639, actor_loss: 6.888499736785889, critic_loss: 0.09816811233758926, \n",
      "training actor, critic...\n",
      "actor loss: 6.67781400680542, critic loss: 0.09136965870857239\n",
      "2024-10-04 10:06:37,756 global_step: 181,epoch: 9, kl_loss: 0.0025060954147341605, reconst_loss: 0.010032261227618675, reward_loss: 0.16391828292933275, actor_loss: 6.67781400680542, critic_loss: 0.09136965870857239, \n",
      "training actor, critic...\n",
      "actor loss: 6.503688812255859, critic loss: 0.08771155029535294\n",
      "2024-10-04 10:06:47,066 global_step: 182,epoch: 9, kl_loss: 0.0023204438371716867, reconst_loss: 0.00818319029497857, reward_loss: 0.12009153401298563, actor_loss: 6.503688812255859, critic_loss: 0.08771155029535294, \n",
      "training actor, critic...\n",
      "actor loss: 6.3719611167907715, critic loss: 0.08762364834547043\n",
      "2024-10-04 10:06:56,304 global_step: 183,epoch: 9, kl_loss: 0.002344072107415722, reconst_loss: 0.00872819949587693, reward_loss: 0.15147346162892955, actor_loss: 6.3719611167907715, critic_loss: 0.08762364834547043, \n",
      "training actor, critic...\n",
      "actor loss: 6.277209281921387, critic loss: 0.08391819894313812\n",
      "2024-10-04 10:07:05,472 global_step: 184,epoch: 9, kl_loss: 0.002420638263824263, reconst_loss: 0.009957461769939686, reward_loss: 0.19219192903612417, actor_loss: 6.277209281921387, critic_loss: 0.08391819894313812, \n",
      "training actor, critic...\n",
      "actor loss: 6.242343425750732, critic loss: 0.08518378436565399\n",
      "2024-10-04 10:07:14,881 global_step: 185,epoch: 9, kl_loss: 0.002309333955945105, reconst_loss: 0.008253280111417478, reward_loss: 0.06885069162390024, actor_loss: 6.242343425750732, critic_loss: 0.08518378436565399, \n",
      "training actor, critic...\n",
      "actor loss: 6.250916481018066, critic loss: 0.08434189110994339\n",
      "2024-10-04 10:07:23,980 global_step: 186,epoch: 9, kl_loss: 0.0023193369092115636, reconst_loss: 0.010307780885118611, reward_loss: 0.14519809306675227, actor_loss: 6.250916481018066, critic_loss: 0.08434189110994339, \n",
      "training actor, critic...\n",
      "actor loss: 6.299580097198486, critic loss: 0.08374100923538208\n",
      "2024-10-04 10:07:33,096 global_step: 187,epoch: 9, kl_loss: 0.0023577748785954806, reconst_loss: 0.008595050455128051, reward_loss: 0.146696505189056, actor_loss: 6.299580097198486, critic_loss: 0.08374100923538208, \n",
      "training actor, critic...\n",
      "actor loss: 6.363686561584473, critic loss: 0.08217739313840866\n",
      "2024-10-04 10:07:42,318 global_step: 188,epoch: 9, kl_loss: 0.0022771573525720407, reconst_loss: 0.011121402361563273, reward_loss: 0.2313927818084972, actor_loss: 6.363686561584473, critic_loss: 0.08217739313840866, \n",
      "training actor, critic...\n",
      "actor loss: 6.457010746002197, critic loss: 0.08116535097360611\n",
      "2024-10-04 10:07:51,235 global_step: 189,epoch: 9, kl_loss: 0.0021928363047274096, reconst_loss: 0.00814741440307425, reward_loss: 0.0784420006592492, actor_loss: 6.457010746002197, critic_loss: 0.08116535097360611, \n",
      "training actor, critic...\n",
      "actor loss: 6.566036701202393, critic loss: 0.08397497236728668\n",
      "2024-10-04 10:08:00,620 global_step: 190,epoch: 9, kl_loss: 0.00230008436067562, reconst_loss: 0.008563523589424332, reward_loss: 0.0999007639807782, actor_loss: 6.566036701202393, critic_loss: 0.08397497236728668, \n",
      "training actor, critic...\n",
      "actor loss: 6.688241958618164, critic loss: 0.08878977596759796\n",
      "2024-10-04 10:08:09,798 global_step: 191,epoch: 9, kl_loss: 0.0021864919298404486, reconst_loss: 0.008068741755369974, reward_loss: 0.06789392185616022, actor_loss: 6.688241958618164, critic_loss: 0.08878977596759796, \n",
      "training actor, critic...\n",
      "actor loss: 6.818050384521484, critic loss: 0.09370538592338562\n",
      "2024-10-04 10:08:18,992 global_step: 192,epoch: 9, kl_loss: 0.002190766050670372, reconst_loss: 0.009302554842160672, reward_loss: 0.09218969092614074, actor_loss: 6.818050384521484, critic_loss: 0.09370538592338562, \n",
      "training actor, critic...\n",
      "actor loss: 6.956355571746826, critic loss: 0.09510907530784607\n",
      "2024-10-04 10:08:28,094 global_step: 193,epoch: 9, kl_loss: 0.0022058579571811216, reconst_loss: 0.00853661152211075, reward_loss: 0.11498600563119944, actor_loss: 6.956355571746826, critic_loss: 0.09510907530784607, \n",
      "training actor, critic...\n",
      "actor loss: 7.102358341217041, critic loss: 0.10157136619091034\n",
      "2024-10-04 10:08:37,161 global_step: 194,epoch: 9, kl_loss: 0.0022083302907531664, reconst_loss: 0.008016447669693403, reward_loss: 0.12997030662325193, actor_loss: 7.102358341217041, critic_loss: 0.10157136619091034, \n",
      "training actor, critic...\n",
      "actor loss: 7.242899417877197, critic loss: 0.10498698055744171\n",
      "2024-10-04 10:08:46,455 global_step: 195,epoch: 9, kl_loss: 0.002184774127921888, reconst_loss: 0.009940722995266622, reward_loss: 0.18884569882149144, actor_loss: 7.242899417877197, critic_loss: 0.10498698055744171, \n",
      "training actor, critic...\n",
      "actor loss: 7.386376857757568, critic loss: 0.10739467293024063\n",
      "2024-10-04 10:08:55,784 global_step: 196,epoch: 9, kl_loss: 0.002151074194425375, reconst_loss: 0.007546781552765443, reward_loss: 0.09012283668354419, actor_loss: 7.386376857757568, critic_loss: 0.10739467293024063, \n",
      "training actor, critic...\n",
      "actor loss: 7.518764972686768, critic loss: 0.11461344361305237\n",
      "2024-10-04 10:09:04,992 global_step: 197,epoch: 9, kl_loss: 0.0021903157668967483, reconst_loss: 0.008079787773289243, reward_loss: 0.13647966004661, actor_loss: 7.518764972686768, critic_loss: 0.11461344361305237, \n",
      "training actor, critic...\n",
      "actor loss: 7.635124206542969, critic loss: 0.11744707077741623\n",
      "2024-10-04 10:09:14,430 global_step: 198,epoch: 9, kl_loss: 0.0021480766519409965, reconst_loss: 0.007894825418384708, reward_loss: 0.10195172971770243, actor_loss: 7.635124206542969, critic_loss: 0.11744707077741623, \n",
      "training actor, critic...\n",
      "actor loss: 7.722183704376221, critic loss: 0.12013586610555649\n",
      "2024-10-04 10:09:23,442 global_step: 199,epoch: 9, kl_loss: 0.0021839825263037824, reconst_loss: 0.009168243862460462, reward_loss: 0.14617740509233304, actor_loss: 7.722183704376221, critic_loss: 0.12013586610555649, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:41<00:00, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:10:04,725 global_step: 180,test_score: -93.3842752200306, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:43<00:00, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:10:48,332 global_step: 200,train_score: -92.99388408127042, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38000\n",
      "training actor, critic...\n",
      "actor loss: 7.78507661819458, critic loss: 0.12300669401884079\n",
      "2024-10-04 10:10:58,828 global_step: 200,epoch: 10, kl_loss: 0.0022102444176086964, reconst_loss: 0.008645693914090492, reward_loss: 0.0977066202820944, actor_loss: 7.78507661819458, critic_loss: 0.12300669401884079, \n",
      "training actor, critic...\n",
      "actor loss: 7.818826198577881, critic loss: 0.1187894269824028\n",
      "2024-10-04 10:11:08,299 global_step: 201,epoch: 10, kl_loss: 0.002081270733544109, reconst_loss: 0.007297686519747486, reward_loss: 0.11293629872997539, actor_loss: 7.818826198577881, critic_loss: 0.1187894269824028, \n",
      "training actor, critic...\n",
      "actor loss: 7.824929237365723, critic loss: 0.12169671803712845\n",
      "2024-10-04 10:11:17,534 global_step: 202,epoch: 10, kl_loss: 0.0021272615579489085, reconst_loss: 0.008140126756411426, reward_loss: 0.1355578833086207, actor_loss: 7.824929237365723, critic_loss: 0.12169671803712845, \n",
      "training actor, critic...\n",
      "actor loss: 7.809103012084961, critic loss: 0.11886677891016006\n",
      "2024-10-04 10:11:26,769 global_step: 203,epoch: 10, kl_loss: 0.002159638034550435, reconst_loss: 0.008038987044473084, reward_loss: 0.1193567897580393, actor_loss: 7.809103012084961, critic_loss: 0.11886677891016006, \n",
      "training actor, critic...\n",
      "actor loss: 7.769486904144287, critic loss: 0.11705546081066132\n",
      "2024-10-04 10:11:35,805 global_step: 204,epoch: 10, kl_loss: 0.002093731253455412, reconst_loss: 0.007891478035979125, reward_loss: 0.15495623248909618, actor_loss: 7.769486904144287, critic_loss: 0.11705546081066132, \n",
      "training actor, critic...\n",
      "actor loss: 7.707803726196289, critic loss: 0.11669791489839554\n",
      "2024-10-04 10:11:45,062 global_step: 205,epoch: 10, kl_loss: 0.002134680958246166, reconst_loss: 0.008957858739078653, reward_loss: 0.1491154808056902, actor_loss: 7.707803726196289, critic_loss: 0.11669791489839554, \n",
      "training actor, critic...\n",
      "actor loss: 7.616429328918457, critic loss: 0.11177504062652588\n",
      "2024-10-04 10:11:54,219 global_step: 206,epoch: 10, kl_loss: 0.002156239552946039, reconst_loss: 0.0090942115389875, reward_loss: 0.20909261044794314, actor_loss: 7.616429328918457, critic_loss: 0.11177504062652588, \n",
      "training actor, critic...\n",
      "actor loss: 7.493973255157471, critic loss: 0.1121085062623024\n",
      "2024-10-04 10:12:03,379 global_step: 207,epoch: 10, kl_loss: 0.00211049656547625, reconst_loss: 0.0074597805719442516, reward_loss: 0.16954371800446616, actor_loss: 7.493973255157471, critic_loss: 0.1121085062623024, \n",
      "training actor, critic...\n",
      "actor loss: 7.333665370941162, critic loss: 0.10355556011199951\n",
      "2024-10-04 10:12:12,470 global_step: 208,epoch: 10, kl_loss: 0.0020654759689338734, reconst_loss: 0.008943242980737467, reward_loss: 0.20507823390059401, actor_loss: 7.333665370941162, critic_loss: 0.10355556011199951, \n",
      "training actor, critic...\n",
      "actor loss: 7.1493682861328125, critic loss: 0.09521869570016861\n",
      "2024-10-04 10:12:21,605 global_step: 209,epoch: 10, kl_loss: 0.0020611524909772737, reconst_loss: 0.007936512433676695, reward_loss: 0.10521687344619435, actor_loss: 7.1493682861328125, critic_loss: 0.09521869570016861, \n",
      "training actor, critic...\n",
      "actor loss: 6.950248718261719, critic loss: 0.08829258382320404\n",
      "2024-10-04 10:12:30,651 global_step: 210,epoch: 10, kl_loss: 0.0020618491131356178, reconst_loss: 0.007633963248179275, reward_loss: 0.07168138641578962, actor_loss: 6.950248718261719, critic_loss: 0.08829258382320404, \n",
      "training actor, critic...\n",
      "actor loss: 6.758201599121094, critic loss: 0.07747253030538559\n",
      "2024-10-04 10:12:39,561 global_step: 211,epoch: 10, kl_loss: 0.002035269788133779, reconst_loss: 0.007664987940949445, reward_loss: 0.06903435149448639, actor_loss: 6.758201599121094, critic_loss: 0.07747253030538559, \n",
      "training actor, critic...\n",
      "actor loss: 6.586884498596191, critic loss: 0.07756198942661285\n",
      "2024-10-04 10:12:48,705 global_step: 212,epoch: 10, kl_loss: 0.0021474362987720843, reconst_loss: 0.008149750454693424, reward_loss: 0.13120815821932819, actor_loss: 6.586884498596191, critic_loss: 0.07756198942661285, \n",
      "training actor, critic...\n",
      "actor loss: 6.459056377410889, critic loss: 0.07906055450439453\n",
      "2024-10-04 10:12:57,661 global_step: 213,epoch: 10, kl_loss: 0.0020242396169532165, reconst_loss: 0.007632862348869747, reward_loss: 0.08785662871942267, actor_loss: 6.459056377410889, critic_loss: 0.07906055450439453, \n",
      "training actor, critic...\n",
      "actor loss: 6.388739585876465, critic loss: 0.08447156846523285\n",
      "2024-10-04 10:13:06,585 global_step: 214,epoch: 10, kl_loss: 0.002022564360083138, reconst_loss: 0.00788843271569634, reward_loss: 0.11359991632492225, actor_loss: 6.388739585876465, critic_loss: 0.08447156846523285, \n",
      "training actor, critic...\n",
      "actor loss: 6.382144451141357, critic loss: 0.08799226582050323\n",
      "2024-10-04 10:13:15,515 global_step: 215,epoch: 10, kl_loss: 0.0020852142657457415, reconst_loss: 0.008011903480759688, reward_loss: 0.11628357573455124, actor_loss: 6.382144451141357, critic_loss: 0.08799226582050323, \n",
      "training actor, critic...\n",
      "actor loss: 6.445173263549805, critic loss: 0.09353197365999222\n",
      "2024-10-04 10:13:24,517 global_step: 216,epoch: 10, kl_loss: 0.00200357445223466, reconst_loss: 0.007966928355091689, reward_loss: 0.08034354014433825, actor_loss: 6.445173263549805, critic_loss: 0.09353197365999222, \n",
      "training actor, critic...\n",
      "actor loss: 6.5765204429626465, critic loss: 0.0966307744383812\n",
      "2024-10-04 10:13:33,739 global_step: 217,epoch: 10, kl_loss: 0.0019840621490421115, reconst_loss: 0.0070476017569248775, reward_loss: 0.08907232675594468, actor_loss: 6.5765204429626465, critic_loss: 0.0966307744383812, \n",
      "training actor, critic...\n",
      "actor loss: 6.764294147491455, critic loss: 0.09754478186368942\n",
      "2024-10-04 10:13:43,024 global_step: 218,epoch: 10, kl_loss: 0.001985227811501875, reconst_loss: 0.008067703910400065, reward_loss: 0.11016690848176652, actor_loss: 6.764294147491455, critic_loss: 0.09754478186368942, \n",
      "training actor, critic...\n",
      "actor loss: 6.99424409866333, critic loss: 0.09734384715557098\n",
      "2024-10-04 10:13:52,276 global_step: 219,epoch: 10, kl_loss: 0.0020347045709578587, reconst_loss: 0.007595626095651972, reward_loss: 0.11525192409955744, actor_loss: 6.99424409866333, critic_loss: 0.09734384715557098, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:35<00:00, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:14:27,626 global_step: 220,train_score: -92.88652091002761, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41000\n",
      "training actor, critic...\n",
      "actor loss: 7.25114631652832, critic loss: 0.09766591340303421\n",
      "2024-10-04 10:14:37,739 global_step: 220,epoch: 11, kl_loss: 0.0019883304865251543, reconst_loss: 0.008403650190377114, reward_loss: 0.15122321035982614, actor_loss: 7.25114631652832, critic_loss: 0.09766591340303421, \n",
      "training actor, critic...\n",
      "actor loss: 7.515231609344482, critic loss: 0.0994890108704567\n",
      "2024-10-04 10:14:46,858 global_step: 221,epoch: 11, kl_loss: 0.0019293130216264756, reconst_loss: 0.008885237093710778, reward_loss: 0.14483394553856355, actor_loss: 7.515231609344482, critic_loss: 0.0994890108704567, \n",
      "training actor, critic...\n",
      "actor loss: 7.760721206665039, critic loss: 0.110483817756176\n",
      "2024-10-04 10:14:55,994 global_step: 222,epoch: 11, kl_loss: 0.0019734513866287483, reconst_loss: 0.008418116547471407, reward_loss: 0.12470754224222572, actor_loss: 7.760721206665039, critic_loss: 0.110483817756176, \n",
      "training actor, critic...\n",
      "actor loss: 7.959385871887207, critic loss: 0.1149030551314354\n",
      "2024-10-04 10:15:05,289 global_step: 223,epoch: 11, kl_loss: 0.0018654009000616794, reconst_loss: 0.007030364705667812, reward_loss: 0.10114041336441451, actor_loss: 7.959385871887207, critic_loss: 0.1149030551314354, \n",
      "training actor, critic...\n",
      "actor loss: 8.092704772949219, critic loss: 0.12866392731666565\n",
      "2024-10-04 10:15:14,560 global_step: 224,epoch: 11, kl_loss: 0.0019017637972197287, reconst_loss: 0.006640280473369117, reward_loss: 0.10177685108097574, actor_loss: 8.092704772949219, critic_loss: 0.12866392731666565, \n",
      "training actor, critic...\n",
      "actor loss: 8.14748477935791, critic loss: 0.1269504725933075\n",
      "2024-10-04 10:15:23,530 global_step: 225,epoch: 11, kl_loss: 0.0018735083939070453, reconst_loss: 0.006748163359885921, reward_loss: 0.11073406798199617, actor_loss: 8.14748477935791, critic_loss: 0.1269504725933075, \n",
      "training actor, critic...\n",
      "actor loss: 8.133421897888184, critic loss: 0.12703518569469452\n",
      "2024-10-04 10:15:32,605 global_step: 226,epoch: 11, kl_loss: 0.0018495530096757017, reconst_loss: 0.006747489291414314, reward_loss: 0.09713995302742233, actor_loss: 8.133421897888184, critic_loss: 0.12703518569469452, \n",
      "training actor, critic...\n",
      "actor loss: 8.062795639038086, critic loss: 0.11899933964014053\n",
      "2024-10-04 10:15:41,852 global_step: 227,epoch: 11, kl_loss: 0.0018944093358836003, reconst_loss: 0.007299416565469333, reward_loss: 0.1080897863293827, actor_loss: 8.062795639038086, critic_loss: 0.11899933964014053, \n",
      "training actor, critic...\n",
      "actor loss: 7.956297397613525, critic loss: 0.11296951025724411\n",
      "2024-10-04 10:15:50,975 global_step: 228,epoch: 11, kl_loss: 0.001802306975670425, reconst_loss: 0.006667606428037493, reward_loss: 0.10177484064301172, actor_loss: 7.956297397613525, critic_loss: 0.11296951025724411, \n",
      "training actor, critic...\n",
      "actor loss: 7.832332611083984, critic loss: 0.10799971222877502\n",
      "2024-10-04 10:16:00,293 global_step: 229,epoch: 11, kl_loss: 0.0018593230717150228, reconst_loss: 0.008018015256645729, reward_loss: 0.10444859002137138, actor_loss: 7.832332611083984, critic_loss: 0.10799971222877502, \n",
      "training actor, critic...\n",
      "actor loss: 7.708226203918457, critic loss: 0.09991269558668137\n",
      "2024-10-04 10:16:09,410 global_step: 230,epoch: 11, kl_loss: 0.0018828615014042174, reconst_loss: 0.008089878339776578, reward_loss: 0.14663858346555533, actor_loss: 7.708226203918457, critic_loss: 0.09991269558668137, \n",
      "training actor, critic...\n",
      "actor loss: 7.593683242797852, critic loss: 0.10048497468233109\n",
      "2024-10-04 10:16:18,504 global_step: 231,epoch: 11, kl_loss: 0.0018721616432564904, reconst_loss: 0.00843933034612208, reward_loss: 0.11339207522794414, actor_loss: 7.593683242797852, critic_loss: 0.10048497468233109, \n",
      "training actor, critic...\n",
      "actor loss: 7.496323108673096, critic loss: 0.09598129987716675\n",
      "2024-10-04 10:16:27,635 global_step: 232,epoch: 11, kl_loss: 0.0018129827625745414, reconst_loss: 0.007746397346562269, reward_loss: 0.12534872399362718, actor_loss: 7.496323108673096, critic_loss: 0.09598129987716675, \n",
      "training actor, critic...\n",
      "actor loss: 7.420467853546143, critic loss: 0.09205914288759232\n",
      "2024-10-04 10:16:36,722 global_step: 233,epoch: 11, kl_loss: 0.0018692011600455307, reconst_loss: 0.007321873119062915, reward_loss: 0.12428387953681225, actor_loss: 7.420467853546143, critic_loss: 0.09205914288759232, \n",
      "training actor, critic...\n",
      "actor loss: 7.361537456512451, critic loss: 0.09202542901039124\n",
      "2024-10-04 10:16:46,086 global_step: 234,epoch: 11, kl_loss: 0.0018637149632737345, reconst_loss: 0.007262581598241718, reward_loss: 0.12249216529284129, actor_loss: 7.361537456512451, critic_loss: 0.09202542901039124, \n",
      "training actor, critic...\n",
      "actor loss: 7.315857887268066, critic loss: 0.0891258642077446\n",
      "2024-10-04 10:16:55,409 global_step: 235,epoch: 11, kl_loss: 0.0017989394617295464, reconst_loss: 0.007804037727491588, reward_loss: 0.11369194744549198, actor_loss: 7.315857887268066, critic_loss: 0.0891258642077446, \n",
      "training actor, critic...\n",
      "actor loss: 7.277642726898193, critic loss: 0.08743733912706375\n",
      "2024-10-04 10:17:04,477 global_step: 236,epoch: 11, kl_loss: 0.001823236722717708, reconst_loss: 0.008401064249705903, reward_loss: 0.17482389559213796, actor_loss: 7.277642726898193, critic_loss: 0.08743733912706375, \n",
      "training actor, critic...\n",
      "actor loss: 7.24382209777832, critic loss: 0.08425737172365189\n",
      "2024-10-04 10:17:13,479 global_step: 237,epoch: 11, kl_loss: 0.0018424296986824852, reconst_loss: 0.006573937538707135, reward_loss: 0.10143473830515976, actor_loss: 7.24382209777832, critic_loss: 0.08425737172365189, \n",
      "training actor, critic...\n",
      "actor loss: 7.212259292602539, critic loss: 0.08496379107236862\n",
      "2024-10-04 10:17:22,457 global_step: 238,epoch: 11, kl_loss: 0.0017996043755615853, reconst_loss: 0.007359566547128619, reward_loss: 0.08667323147113036, actor_loss: 7.212259292602539, critic_loss: 0.08496379107236862, \n",
      "training actor, critic...\n",
      "actor loss: 7.174877643585205, critic loss: 0.08194898813962936\n",
      "2024-10-04 10:17:31,620 global_step: 239,epoch: 11, kl_loss: 0.0018020386193470306, reconst_loss: 0.0080054889109974, reward_loss: 0.12935151517681054, actor_loss: 7.174877643585205, critic_loss: 0.08194898813962936, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:34<00:00, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:18:05,842 global_step: 240,train_score: -92.42330528993232, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44000\n",
      "training actor, critic...\n",
      "actor loss: 7.144186973571777, critic loss: 0.08179407566785812\n",
      "2024-10-04 10:18:17,320 global_step: 240,epoch: 12, kl_loss: 0.001796928675113512, reconst_loss: 0.006320697844636684, reward_loss: 0.07598491078860374, actor_loss: 7.144186973571777, critic_loss: 0.08179407566785812, \n",
      "training actor, critic...\n",
      "actor loss: 7.119193077087402, critic loss: 0.08077140897512436\n",
      "2024-10-04 10:18:26,670 global_step: 241,epoch: 12, kl_loss: 0.0017596960307707135, reconst_loss: 0.00722624824325345, reward_loss: 0.12023428733322808, actor_loss: 7.119193077087402, critic_loss: 0.08077140897512436, \n",
      "training actor, critic...\n",
      "actor loss: 7.102990627288818, critic loss: 0.07881191372871399\n",
      "2024-10-04 10:18:35,888 global_step: 242,epoch: 12, kl_loss: 0.0017590092427372857, reconst_loss: 0.007766656235468631, reward_loss: 0.10823400408903859, actor_loss: 7.102990627288818, critic_loss: 0.07881191372871399, \n",
      "training actor, critic...\n",
      "actor loss: 7.109726428985596, critic loss: 0.07968112826347351\n",
      "2024-10-04 10:18:45,082 global_step: 243,epoch: 12, kl_loss: 0.0017372595635717924, reconst_loss: 0.005996770263478464, reward_loss: 0.08495769098434332, actor_loss: 7.109726428985596, critic_loss: 0.07968112826347351, \n",
      "training actor, critic...\n",
      "actor loss: 7.136917591094971, critic loss: 0.08355932682752609\n",
      "2024-10-04 10:18:54,465 global_step: 244,epoch: 12, kl_loss: 0.0017456167379907351, reconst_loss: 0.007899207405137772, reward_loss: 0.13726373454579627, actor_loss: 7.136917591094971, critic_loss: 0.08355932682752609, \n",
      "training actor, critic...\n",
      "actor loss: 7.197346210479736, critic loss: 0.08406966924667358\n",
      "2024-10-04 10:19:04,024 global_step: 245,epoch: 12, kl_loss: 0.0017241171462584895, reconst_loss: 0.006824230917786457, reward_loss: 0.06186111317828716, actor_loss: 7.197346210479736, critic_loss: 0.08406966924667358, \n",
      "training actor, critic...\n",
      "actor loss: 7.289155006408691, critic loss: 0.08717095106840134\n",
      "2024-10-04 10:19:13,403 global_step: 246,epoch: 12, kl_loss: 0.0017027472227821316, reconst_loss: 0.007450134807019209, reward_loss: 0.09006434339229302, actor_loss: 7.289155006408691, critic_loss: 0.08717095106840134, \n",
      "training actor, critic...\n",
      "actor loss: 7.417306900024414, critic loss: 0.09332134574651718\n",
      "2024-10-04 10:19:22,652 global_step: 247,epoch: 12, kl_loss: 0.001694964263374366, reconst_loss: 0.007327579142411752, reward_loss: 0.08256783284845629, actor_loss: 7.417306900024414, critic_loss: 0.09332134574651718, \n",
      "training actor, critic...\n",
      "actor loss: 7.581183433532715, critic loss: 0.09791628271341324\n",
      "2024-10-04 10:19:31,871 global_step: 248,epoch: 12, kl_loss: 0.0016560258993603364, reconst_loss: 0.006866043062918648, reward_loss: 0.10705874109972145, actor_loss: 7.581183433532715, critic_loss: 0.09791628271341324, \n",
      "training actor, critic...\n",
      "actor loss: 7.773976802825928, critic loss: 0.09970835596323013\n",
      "2024-10-04 10:19:41,054 global_step: 249,epoch: 12, kl_loss: 0.0016539629574922122, reconst_loss: 0.006778022968115247, reward_loss: 0.0920031991584122, actor_loss: 7.773976802825928, critic_loss: 0.09970835596323013, \n",
      "training actor, critic...\n",
      "actor loss: 7.98440408706665, critic loss: 0.10352656990289688\n",
      "2024-10-04 10:19:50,707 global_step: 250,epoch: 12, kl_loss: 0.0016937446994326857, reconst_loss: 0.006801676841414705, reward_loss: 0.14808373387940987, actor_loss: 7.98440408706665, critic_loss: 0.10352656990289688, \n",
      "training actor, critic...\n",
      "actor loss: 8.205391883850098, critic loss: 0.10989148914813995\n",
      "2024-10-04 10:20:00,331 global_step: 251,epoch: 12, kl_loss: 0.0016322572874760597, reconst_loss: 0.006036828386084158, reward_loss: 0.1109098419734177, actor_loss: 8.205391883850098, critic_loss: 0.10989148914813995, \n",
      "training actor, critic...\n",
      "actor loss: 8.40401554107666, critic loss: 0.11656074225902557\n",
      "2024-10-04 10:20:09,771 global_step: 252,epoch: 12, kl_loss: 0.0016684538823771005, reconst_loss: 0.008196216276181596, reward_loss: 0.2009514658385175, actor_loss: 8.40401554107666, critic_loss: 0.11656074225902557, \n",
      "training actor, critic...\n",
      "actor loss: 8.568937301635742, critic loss: 0.11995961517095566\n",
      "2024-10-04 10:20:18,972 global_step: 253,epoch: 12, kl_loss: 0.0016205316380958777, reconst_loss: 0.006302103086621786, reward_loss: 0.06326506098872525, actor_loss: 8.568937301635742, critic_loss: 0.11995961517095566, \n",
      "training actor, critic...\n",
      "actor loss: 8.661260604858398, critic loss: 0.13072727620601654\n",
      "2024-10-04 10:20:28,036 global_step: 254,epoch: 12, kl_loss: 0.0016487805595697493, reconst_loss: 0.007118369015503903, reward_loss: 0.17271022343110026, actor_loss: 8.661260604858398, critic_loss: 0.13072727620601654, \n",
      "training actor, critic...\n",
      "actor loss: 8.670485496520996, critic loss: 0.13047879934310913\n",
      "2024-10-04 10:20:37,551 global_step: 255,epoch: 12, kl_loss: 0.001581208934242438, reconst_loss: 0.007617631527994361, reward_loss: 0.12660172853466808, actor_loss: 8.670485496520996, critic_loss: 0.13047879934310913, \n",
      "training actor, critic...\n",
      "actor loss: 8.587153434753418, critic loss: 0.13490073382854462\n",
      "2024-10-04 10:20:46,758 global_step: 256,epoch: 12, kl_loss: 0.0016442073939121043, reconst_loss: 0.00747614056442161, reward_loss: 0.1723825354235988, actor_loss: 8.587153434753418, critic_loss: 0.13490073382854462, \n",
      "training actor, critic...\n",
      "actor loss: 8.423112869262695, critic loss: 0.129720538854599\n",
      "2024-10-04 10:20:55,828 global_step: 257,epoch: 12, kl_loss: 0.0016691986493984883, reconst_loss: 0.007973890856136473, reward_loss: 0.12312594614210254, actor_loss: 8.423112869262695, critic_loss: 0.129720538854599, \n",
      "training actor, critic...\n",
      "actor loss: 8.196280479431152, critic loss: 0.11565560847520828\n",
      "2024-10-04 10:21:04,835 global_step: 258,epoch: 12, kl_loss: 0.001539890645475754, reconst_loss: 0.0070364819459465084, reward_loss: 0.1540990619105287, actor_loss: 8.196280479431152, critic_loss: 0.11565560847520828, \n",
      "training actor, critic...\n",
      "actor loss: 7.925477027893066, critic loss: 0.10421536862850189\n",
      "2024-10-04 10:21:14,146 global_step: 259,epoch: 12, kl_loss: 0.0015145424178478364, reconst_loss: 0.006915401040139247, reward_loss: 0.1481129848065653, actor_loss: 7.925477027893066, critic_loss: 0.10421536862850189, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:42<00:00, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:21:56,337 global_step: 240,test_score: -93.19098107785844, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:42<00:00, 14.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:22:38,481 global_step: 260,train_score: -92.79304921184935, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47000\n",
      "training actor, critic...\n",
      "actor loss: 7.639471054077148, critic loss: 0.09071583300828934\n",
      "2024-10-04 10:22:48,385 global_step: 260,epoch: 13, kl_loss: 0.001578702841414975, reconst_loss: 0.006859782665055625, reward_loss: 0.09840520209756357, actor_loss: 7.639471054077148, critic_loss: 0.09071583300828934, \n",
      "training actor, critic...\n",
      "actor loss: 7.35458517074585, critic loss: 0.0791340097784996\n",
      "2024-10-04 10:22:57,578 global_step: 261,epoch: 13, kl_loss: 0.0015081772735171324, reconst_loss: 0.006295794972731751, reward_loss: 0.07412525951121078, actor_loss: 7.35458517074585, critic_loss: 0.0791340097784996, \n",
      "training actor, critic...\n",
      "actor loss: 7.087250709533691, critic loss: 0.07351567596197128\n",
      "2024-10-04 10:23:06,834 global_step: 262,epoch: 13, kl_loss: 0.0015424423374720297, reconst_loss: 0.00690465794914231, reward_loss: 0.15628560003824532, actor_loss: 7.087250709533691, critic_loss: 0.07351567596197128, \n",
      "training actor, critic...\n",
      "actor loss: 6.858292102813721, critic loss: 0.06717406958341599\n",
      "2024-10-04 10:23:16,147 global_step: 263,epoch: 13, kl_loss: 0.0015475380428049865, reconst_loss: 0.007153402443747132, reward_loss: 0.09788633958075424, actor_loss: 6.858292102813721, critic_loss: 0.06717406958341599, \n",
      "training actor, critic...\n",
      "actor loss: 6.671626567840576, critic loss: 0.06628577411174774\n",
      "2024-10-04 10:23:25,493 global_step: 264,epoch: 13, kl_loss: 0.0014574177389755389, reconst_loss: 0.0071397029452634105, reward_loss: 0.15421120915324332, actor_loss: 6.671626567840576, critic_loss: 0.06628577411174774, \n",
      "training actor, critic...\n",
      "actor loss: 6.528671741485596, critic loss: 0.06607194244861603\n",
      "2024-10-04 10:23:34,565 global_step: 265,epoch: 13, kl_loss: 0.0014583356203321293, reconst_loss: 0.006603043773496638, reward_loss: 0.17955938790692016, actor_loss: 6.528671741485596, critic_loss: 0.06607194244861603, \n",
      "training actor, critic...\n",
      "actor loss: 6.434845924377441, critic loss: 0.06450903415679932\n",
      "2024-10-04 10:23:43,972 global_step: 266,epoch: 13, kl_loss: 0.0016221030922939203, reconst_loss: 0.007114451007955536, reward_loss: 0.14277080598890743, actor_loss: 6.434845924377441, critic_loss: 0.06450903415679932, \n",
      "training actor, critic...\n",
      "actor loss: 6.3933258056640625, critic loss: 0.06407187879085541\n",
      "2024-10-04 10:23:53,356 global_step: 267,epoch: 13, kl_loss: 0.001448797688068708, reconst_loss: 0.005872538170720242, reward_loss: 0.0722787687709384, actor_loss: 6.3933258056640625, critic_loss: 0.06407187879085541, \n",
      "training actor, critic...\n",
      "actor loss: 6.404958248138428, critic loss: 0.06666017323732376\n",
      "2024-10-04 10:24:02,607 global_step: 268,epoch: 13, kl_loss: 0.001452796404696621, reconst_loss: 0.005761447685713671, reward_loss: 0.058773548090450316, actor_loss: 6.404958248138428, critic_loss: 0.06666017323732376, \n",
      "training actor, critic...\n",
      "actor loss: 6.463834285736084, critic loss: 0.07151082158088684\n",
      "2024-10-04 10:24:11,812 global_step: 269,epoch: 13, kl_loss: 0.0016157752780804448, reconst_loss: 0.0058236885910891755, reward_loss: 0.09138075255537026, actor_loss: 6.463834285736084, critic_loss: 0.07151082158088684, \n",
      "training actor, critic...\n",
      "actor loss: 6.5596604347229, critic loss: 0.07130376249551773\n",
      "2024-10-04 10:24:20,986 global_step: 270,epoch: 13, kl_loss: 0.0014815993110497234, reconst_loss: 0.006747281112309013, reward_loss: 0.12416313337969917, actor_loss: 6.5596604347229, critic_loss: 0.07130376249551773, \n",
      "training actor, critic...\n",
      "actor loss: 6.693902492523193, critic loss: 0.07313298434019089\n",
      "2024-10-04 10:24:30,170 global_step: 271,epoch: 13, kl_loss: 0.0014840945855676367, reconst_loss: 0.007153865263550257, reward_loss: 0.09828418715113336, actor_loss: 6.693902492523193, critic_loss: 0.07313298434019089, \n",
      "training actor, critic...\n",
      "actor loss: 6.855465412139893, critic loss: 0.07316891103982925\n",
      "2024-10-04 10:24:39,482 global_step: 272,epoch: 13, kl_loss: 0.0015501098063470302, reconst_loss: 0.005938470002491863, reward_loss: 0.14253977348740518, actor_loss: 6.855465412139893, critic_loss: 0.07316891103982925, \n",
      "training actor, critic...\n",
      "actor loss: 7.046032428741455, critic loss: 0.07642863690853119\n",
      "2024-10-04 10:24:48,551 global_step: 273,epoch: 13, kl_loss: 0.0014684469746758363, reconst_loss: 0.00606323260699912, reward_loss: 0.07513348523311184, actor_loss: 7.046032428741455, critic_loss: 0.07642863690853119, \n",
      "training actor, critic...\n",
      "actor loss: 7.2512664794921875, critic loss: 0.0797153189778328\n",
      "2024-10-04 10:24:57,753 global_step: 274,epoch: 13, kl_loss: 0.0014509753132837691, reconst_loss: 0.0062672665190635895, reward_loss: 0.10319538899086778, actor_loss: 7.2512664794921875, critic_loss: 0.0797153189778328, \n",
      "training actor, critic...\n",
      "actor loss: 7.459314346313477, critic loss: 0.0812608003616333\n",
      "2024-10-04 10:25:06,920 global_step: 275,epoch: 13, kl_loss: 0.0015386123375311419, reconst_loss: 0.008695420904123053, reward_loss: 0.16626397490902917, actor_loss: 7.459314346313477, critic_loss: 0.0812608003616333, \n",
      "training actor, critic...\n",
      "actor loss: 7.659049987792969, critic loss: 0.08804185688495636\n",
      "2024-10-04 10:25:16,401 global_step: 276,epoch: 13, kl_loss: 0.001483741265065892, reconst_loss: 0.006761377648811559, reward_loss: 0.131150014824424, actor_loss: 7.659049987792969, critic_loss: 0.08804185688495636, \n",
      "training actor, critic...\n",
      "actor loss: 7.844725131988525, critic loss: 0.08889211714267731\n",
      "2024-10-04 10:25:25,700 global_step: 277,epoch: 13, kl_loss: 0.0014535745110467303, reconst_loss: 0.006344107749434758, reward_loss: 0.09623672609212713, actor_loss: 7.844725131988525, critic_loss: 0.08889211714267731, \n",
      "training actor, critic...\n",
      "actor loss: 7.998222351074219, critic loss: 0.09698330610990524\n",
      "2024-10-04 10:25:34,919 global_step: 278,epoch: 13, kl_loss: 0.0014896402485925248, reconst_loss: 0.007428480853915823, reward_loss: 0.12811552445114383, actor_loss: 7.998222351074219, critic_loss: 0.09698330610990524, \n",
      "training actor, critic...\n",
      "actor loss: 8.118868827819824, critic loss: 0.10053907334804535\n",
      "2024-10-04 10:25:44,127 global_step: 279,epoch: 13, kl_loss: 0.0014556641025202616, reconst_loss: 0.006355157844266113, reward_loss: 0.10888079190816806, actor_loss: 8.118868827819824, critic_loss: 0.10053907334804535, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:35<00:00, 11.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:26:20,099 global_step: 280,train_score: -93.04741937602125, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "training actor, critic...\n",
      "actor loss: 8.200356483459473, critic loss: 0.10307971388101578\n",
      "2024-10-04 10:26:30,965 global_step: 280,epoch: 14, kl_loss: 0.0013950298527227144, reconst_loss: 0.005791434704573179, reward_loss: 0.09717648277981017, actor_loss: 8.200356483459473, critic_loss: 0.10307971388101578, \n",
      "training actor, critic...\n",
      "actor loss: 8.242693901062012, critic loss: 0.1031142994761467\n",
      "2024-10-04 10:26:39,933 global_step: 281,epoch: 14, kl_loss: 0.0014950590741545037, reconst_loss: 0.006276183885199075, reward_loss: 0.08475098198835682, actor_loss: 8.242693901062012, critic_loss: 0.1031142994761467, \n",
      "training actor, critic...\n",
      "actor loss: 8.247540473937988, critic loss: 0.10287461429834366\n",
      "2024-10-04 10:26:48,977 global_step: 282,epoch: 14, kl_loss: 0.001482019520469238, reconst_loss: 0.007792228291153299, reward_loss: 0.13198339791103667, actor_loss: 8.247540473937988, critic_loss: 0.10287461429834366, \n",
      "training actor, critic...\n",
      "actor loss: 8.219576835632324, critic loss: 0.1008271649479866\n",
      "2024-10-04 10:26:58,126 global_step: 283,epoch: 14, kl_loss: 0.0014784701289704107, reconst_loss: 0.0067403900094938525, reward_loss: 0.16446868307075976, actor_loss: 8.219576835632324, critic_loss: 0.1008271649479866, \n",
      "training actor, critic...\n",
      "actor loss: 8.170475006103516, critic loss: 0.09829995781183243\n",
      "2024-10-04 10:27:07,196 global_step: 284,epoch: 14, kl_loss: 0.0014338153479763363, reconst_loss: 0.005177991208145205, reward_loss: 0.05962306614822651, actor_loss: 8.170475006103516, critic_loss: 0.09829995781183243, \n",
      "training actor, critic...\n",
      "actor loss: 8.10284423828125, critic loss: 0.09433050453662872\n",
      "2024-10-04 10:27:16,389 global_step: 285,epoch: 14, kl_loss: 0.0014518428064065473, reconst_loss: 0.006277977583967909, reward_loss: 0.1320043841545584, actor_loss: 8.10284423828125, critic_loss: 0.09433050453662872, \n",
      "training actor, critic...\n",
      "actor loss: 8.026013374328613, critic loss: 0.09006305038928986\n",
      "2024-10-04 10:27:25,445 global_step: 286,epoch: 14, kl_loss: 0.0013961182361972347, reconst_loss: 0.0051285382645318706, reward_loss: 0.09253879008596116, actor_loss: 8.026013374328613, critic_loss: 0.09006305038928986, \n",
      "training actor, critic...\n",
      "actor loss: 7.945500373840332, critic loss: 0.08886392414569855\n",
      "2024-10-04 10:27:34,576 global_step: 287,epoch: 14, kl_loss: 0.0014428480511070325, reconst_loss: 0.006065124845398324, reward_loss: 0.10793496054188557, actor_loss: 7.945500373840332, critic_loss: 0.08886392414569855, \n",
      "training actor, critic...\n",
      "actor loss: 7.864555358886719, critic loss: 0.08635038882493973\n",
      "2024-10-04 10:27:43,886 global_step: 288,epoch: 14, kl_loss: 0.0014513640691839842, reconst_loss: 0.00668399219344161, reward_loss: 0.14139125669465344, actor_loss: 7.864555358886719, critic_loss: 0.08635038882493973, \n",
      "training actor, critic...\n",
      "actor loss: 7.787900924682617, critic loss: 0.08572649955749512\n",
      "2024-10-04 10:27:53,015 global_step: 289,epoch: 14, kl_loss: 0.0014470123753607348, reconst_loss: 0.006084516036267184, reward_loss: 0.10171224473623977, actor_loss: 7.787900924682617, critic_loss: 0.08572649955749512, \n",
      "training actor, critic...\n",
      "actor loss: 7.721154689788818, critic loss: 0.08203175663948059\n",
      "2024-10-04 10:28:01,937 global_step: 290,epoch: 14, kl_loss: 0.0014790180344158327, reconst_loss: 0.0057957723299611585, reward_loss: 0.10476922143217442, actor_loss: 7.721154689788818, critic_loss: 0.08203175663948059, \n",
      "training actor, critic...\n",
      "actor loss: 7.662906169891357, critic loss: 0.08184801042079926\n",
      "2024-10-04 10:28:10,918 global_step: 291,epoch: 14, kl_loss: 0.0014540359009014518, reconst_loss: 0.006513320337220722, reward_loss: 0.12467557081729363, actor_loss: 7.662906169891357, critic_loss: 0.08184801042079926, \n",
      "training actor, critic...\n",
      "actor loss: 7.616722106933594, critic loss: 0.07817807793617249\n",
      "2024-10-04 10:28:20,068 global_step: 292,epoch: 14, kl_loss: 0.0014376676456090442, reconst_loss: 0.006106758651760768, reward_loss: 0.09257788897838862, actor_loss: 7.616722106933594, critic_loss: 0.07817807793617249, \n",
      "training actor, critic...\n",
      "actor loss: 7.580464839935303, critic loss: 0.07686704397201538\n",
      "2024-10-04 10:28:29,284 global_step: 293,epoch: 14, kl_loss: 0.0014254491971045428, reconst_loss: 0.006278463667828818, reward_loss: 0.15416989968353123, actor_loss: 7.580464839935303, critic_loss: 0.07686704397201538, \n",
      "training actor, critic...\n",
      "actor loss: 7.553258895874023, critic loss: 0.07880742102861404\n",
      "2024-10-04 10:28:38,657 global_step: 294,epoch: 14, kl_loss: 0.001454222141955124, reconst_loss: 0.006310664354918563, reward_loss: 0.10949131554676866, actor_loss: 7.553258895874023, critic_loss: 0.07880742102861404, \n",
      "training actor, critic...\n",
      "actor loss: 7.531195640563965, critic loss: 0.0724467858672142\n",
      "2024-10-04 10:28:47,756 global_step: 295,epoch: 14, kl_loss: 0.0014407054615582396, reconst_loss: 0.00655762720092827, reward_loss: 0.14527217735422357, actor_loss: 7.531195640563965, critic_loss: 0.0724467858672142, \n",
      "training actor, critic...\n",
      "actor loss: 7.520726680755615, critic loss: 0.0747959241271019\n",
      "2024-10-04 10:28:56,738 global_step: 296,epoch: 14, kl_loss: 0.0014262526698187183, reconst_loss: 0.005799028765866343, reward_loss: 0.04204568267878316, actor_loss: 7.520726680755615, critic_loss: 0.0747959241271019, \n",
      "training actor, critic...\n",
      "actor loss: 7.519021511077881, critic loss: 0.07599413394927979\n",
      "2024-10-04 10:29:05,704 global_step: 297,epoch: 14, kl_loss: 0.0014256961395422338, reconst_loss: 0.005453689831632132, reward_loss: 0.06219446158621042, actor_loss: 7.519021511077881, critic_loss: 0.07599413394927979, \n",
      "training actor, critic...\n",
      "actor loss: 7.525492191314697, critic loss: 0.0738598182797432\n",
      "2024-10-04 10:29:14,801 global_step: 298,epoch: 14, kl_loss: 0.0014155780322189272, reconst_loss: 0.006537833213045889, reward_loss: 0.11629903711894128, actor_loss: 7.525492191314697, critic_loss: 0.0738598182797432, \n",
      "training actor, critic...\n",
      "actor loss: 7.538612365722656, critic loss: 0.0756165087223053\n",
      "2024-10-04 10:29:24,029 global_step: 299,epoch: 14, kl_loss: 0.0014051804238840063, reconst_loss: 0.007275460639550369, reward_loss: 0.14371014797551634, actor_loss: 7.538612365722656, critic_loss: 0.0756165087223053, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:42<00:00, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:30:06,647 global_step: 300,train_score: -93.0860847994772, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53000\n",
      "training actor, critic...\n",
      "actor loss: 7.559849739074707, critic loss: 0.0726112574338913\n",
      "2024-10-04 10:30:19,992 global_step: 300,epoch: 15, kl_loss: 0.0013714549734556516, reconst_loss: 0.005722367964989069, reward_loss: 0.09105832335700718, actor_loss: 7.559849739074707, critic_loss: 0.0726112574338913, \n",
      "training actor, critic...\n",
      "actor loss: 7.591652870178223, critic loss: 0.07611655443906784\n",
      "2024-10-04 10:30:29,428 global_step: 301,epoch: 15, kl_loss: 0.0014227870884422707, reconst_loss: 0.006111837362832561, reward_loss: 0.11016790799520985, actor_loss: 7.591652870178223, critic_loss: 0.07611655443906784, \n",
      "training actor, critic...\n",
      "actor loss: 7.630435466766357, critic loss: 0.07591193914413452\n",
      "2024-10-04 10:30:38,803 global_step: 302,epoch: 15, kl_loss: 0.0013845335429044897, reconst_loss: 0.005399550168718003, reward_loss: 0.12008366489198477, actor_loss: 7.630435466766357, critic_loss: 0.07591193914413452, \n",
      "training actor, critic...\n",
      "actor loss: 7.675459861755371, critic loss: 0.07752620428800583\n",
      "2024-10-04 10:30:48,268 global_step: 303,epoch: 15, kl_loss: 0.0014260911500931965, reconst_loss: 0.005914737175845978, reward_loss: 0.09270093330403087, actor_loss: 7.675459861755371, critic_loss: 0.07752620428800583, \n",
      "training actor, critic...\n",
      "actor loss: 7.724075794219971, critic loss: 0.07711893320083618\n",
      "2024-10-04 10:30:57,772 global_step: 304,epoch: 15, kl_loss: 0.0013864276463246656, reconst_loss: 0.006141091050694184, reward_loss: 0.07736073755801712, actor_loss: 7.724075794219971, critic_loss: 0.07711893320083618, \n",
      "training actor, critic...\n",
      "actor loss: 7.783580303192139, critic loss: 0.07960619777441025\n",
      "2024-10-04 10:31:06,965 global_step: 305,epoch: 15, kl_loss: 0.0013504597092313425, reconst_loss: 0.005068532561845317, reward_loss: 0.05941223378746999, actor_loss: 7.783580303192139, critic_loss: 0.07960619777441025, \n",
      "training actor, critic...\n",
      "actor loss: 7.843822479248047, critic loss: 0.07896816730499268\n",
      "2024-10-04 10:31:16,239 global_step: 306,epoch: 15, kl_loss: 0.001326142832261453, reconst_loss: 0.0062806776211578015, reward_loss: 0.12736580558525093, actor_loss: 7.843822479248047, critic_loss: 0.07896816730499268, \n",
      "training actor, critic...\n",
      "actor loss: 7.903604030609131, critic loss: 0.08268776535987854\n",
      "2024-10-04 10:31:25,413 global_step: 307,epoch: 15, kl_loss: 0.00134568879195508, reconst_loss: 0.007037409239125495, reward_loss: 0.1655667296632155, actor_loss: 7.903604030609131, critic_loss: 0.08268776535987854, \n",
      "training actor, critic...\n",
      "actor loss: 7.964530944824219, critic loss: 0.08009705692529678\n",
      "2024-10-04 10:31:34,569 global_step: 308,epoch: 15, kl_loss: 0.0013490970016632952, reconst_loss: 0.0058021197399618675, reward_loss: 0.08737253774152308, actor_loss: 7.964530944824219, critic_loss: 0.08009705692529678, \n",
      "training actor, critic...\n",
      "actor loss: 8.01591682434082, critic loss: 0.08197636902332306\n",
      "2024-10-04 10:31:44,187 global_step: 309,epoch: 15, kl_loss: 0.0013602654400937334, reconst_loss: 0.006771726267678397, reward_loss: 0.16650005044446478, actor_loss: 8.01591682434082, critic_loss: 0.08197636902332306, \n",
      "training actor, critic...\n",
      "actor loss: 8.060705184936523, critic loss: 0.08250241726636887\n",
      "2024-10-04 10:31:53,512 global_step: 310,epoch: 15, kl_loss: 0.0012783067053236182, reconst_loss: 0.005126181058585644, reward_loss: 0.06637316795864276, actor_loss: 8.060705184936523, critic_loss: 0.08250241726636887, \n",
      "training actor, critic...\n",
      "actor loss: 8.085890769958496, critic loss: 0.08198138326406479\n",
      "2024-10-04 10:32:03,014 global_step: 311,epoch: 15, kl_loss: 0.001290774596522429, reconst_loss: 0.005136920557338364, reward_loss: 0.11298269047152384, actor_loss: 8.085890769958496, critic_loss: 0.08198138326406479, \n",
      "training actor, critic...\n",
      "actor loss: 8.089895248413086, critic loss: 0.08520222455263138\n",
      "2024-10-04 10:32:12,331 global_step: 312,epoch: 15, kl_loss: 0.0012564498720909183, reconst_loss: 0.0057933927105017465, reward_loss: 0.18833311008436757, actor_loss: 8.089895248413086, critic_loss: 0.08520222455263138, \n",
      "training actor, critic...\n",
      "actor loss: 8.071242332458496, critic loss: 0.08327358216047287\n",
      "2024-10-04 10:32:21,770 global_step: 313,epoch: 15, kl_loss: 0.0012548228622442682, reconst_loss: 0.004648941763847762, reward_loss: 0.054732241481305004, actor_loss: 8.071242332458496, critic_loss: 0.08327358216047287, \n",
      "training actor, critic...\n",
      "actor loss: 8.031927108764648, critic loss: 0.08421637862920761\n",
      "2024-10-04 10:32:31,298 global_step: 314,epoch: 15, kl_loss: 0.001308556255582739, reconst_loss: 0.006419370378538662, reward_loss: 0.10980233998983452, actor_loss: 8.031927108764648, critic_loss: 0.08421637862920761, \n",
      "training actor, critic...\n",
      "actor loss: 7.976527690887451, critic loss: 0.07973373681306839\n",
      "2024-10-04 10:32:40,806 global_step: 315,epoch: 15, kl_loss: 0.0013110646924564652, reconst_loss: 0.006030457284377545, reward_loss: 0.05921425409757589, actor_loss: 7.976527690887451, critic_loss: 0.07973373681306839, \n",
      "training actor, critic...\n",
      "actor loss: 7.91352653503418, critic loss: 0.07608138769865036\n",
      "2024-10-04 10:32:50,334 global_step: 316,epoch: 15, kl_loss: 0.0012747347628108549, reconst_loss: 0.005486206075518715, reward_loss: 0.05378128925685258, actor_loss: 7.91352653503418, critic_loss: 0.07608138769865036, \n",
      "training actor, critic...\n",
      "actor loss: 7.855676174163818, critic loss: 0.0755929946899414\n",
      "2024-10-04 10:32:59,588 global_step: 317,epoch: 15, kl_loss: 0.0012512371904449537, reconst_loss: 0.006439260644268016, reward_loss: 0.0645451231904765, actor_loss: 7.855676174163818, critic_loss: 0.0755929946899414, \n",
      "training actor, critic...\n",
      "actor loss: 7.803677082061768, critic loss: 0.07646530866622925\n",
      "2024-10-04 10:33:09,100 global_step: 318,epoch: 15, kl_loss: 0.001254388565679879, reconst_loss: 0.006897720517780708, reward_loss: 0.1375212701333316, actor_loss: 7.803677082061768, critic_loss: 0.07646530866622925, \n",
      "training actor, critic...\n",
      "actor loss: 7.772807598114014, critic loss: 0.07444322854280472\n",
      "2024-10-04 10:33:18,523 global_step: 319,epoch: 15, kl_loss: 0.0012398693076220854, reconst_loss: 0.005360776549015118, reward_loss: 0.11311827672049118, actor_loss: 7.772807598114014, critic_loss: 0.07444322854280472, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:40<00:00, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:33:58,898 global_step: 300,test_score: -93.30420405970888, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:41<00:00, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:34:40,526 global_step: 320,train_score: -92.97004692073263, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000\n",
      "training actor, critic...\n",
      "actor loss: 7.761111736297607, critic loss: 0.07217442989349365\n",
      "2024-10-04 10:34:50,501 global_step: 320,epoch: 16, kl_loss: 0.0012375323205226461, reconst_loss: 0.005663793477020702, reward_loss: 0.17234579206216244, actor_loss: 7.761111736297607, critic_loss: 0.07217442989349365, \n",
      "training actor, critic...\n",
      "actor loss: 7.763628959655762, critic loss: 0.07441224902868271\n",
      "2024-10-04 10:34:59,829 global_step: 321,epoch: 16, kl_loss: 0.0012707863028555615, reconst_loss: 0.006341393324261417, reward_loss: 0.1358437740905638, actor_loss: 7.763628959655762, critic_loss: 0.07441224902868271, \n",
      "training actor, critic...\n",
      "actor loss: 7.784878253936768, critic loss: 0.07166476547718048\n",
      "2024-10-04 10:35:08,973 global_step: 322,epoch: 16, kl_loss: 0.001187611624303901, reconst_loss: 0.005353522135362942, reward_loss: 0.06049851672569461, actor_loss: 7.784878253936768, critic_loss: 0.07166476547718048, \n",
      "training actor, critic...\n",
      "actor loss: 7.820186614990234, critic loss: 0.07283084094524384\n",
      "2024-10-04 10:35:18,180 global_step: 323,epoch: 16, kl_loss: 0.0012470950614257089, reconst_loss: 0.0059856573803996555, reward_loss: 0.0639592022052966, actor_loss: 7.820186614990234, critic_loss: 0.07283084094524384, \n",
      "training actor, critic...\n",
      "actor loss: 7.864764213562012, critic loss: 0.07420032471418381\n",
      "2024-10-04 10:35:27,373 global_step: 324,epoch: 16, kl_loss: 0.001242248632776437, reconst_loss: 0.005449252706781334, reward_loss: 0.08766333271906122, actor_loss: 7.864764213562012, critic_loss: 0.07420032471418381, \n",
      "training actor, critic...\n",
      "actor loss: 7.912290096282959, critic loss: 0.07708130031824112\n",
      "2024-10-04 10:35:36,783 global_step: 325,epoch: 16, kl_loss: 0.0011978778508206715, reconst_loss: 0.005394068375533941, reward_loss: 0.0864889689790066, actor_loss: 7.912290096282959, critic_loss: 0.07708130031824112, \n",
      "training actor, critic...\n",
      "actor loss: 7.962048053741455, critic loss: 0.07497897744178772\n",
      "2024-10-04 10:35:46,338 global_step: 326,epoch: 16, kl_loss: 0.0012841161120117509, reconst_loss: 0.005334097521417603, reward_loss: 0.12678710116330077, actor_loss: 7.962048053741455, critic_loss: 0.07497897744178772, \n",
      "training actor, critic...\n",
      "actor loss: 8.006485939025879, critic loss: 0.07508249580860138\n",
      "2024-10-04 10:35:55,514 global_step: 327,epoch: 16, kl_loss: 0.0011638849468816224, reconst_loss: 0.0059387361041593305, reward_loss: 0.09256781791859515, actor_loss: 8.006485939025879, critic_loss: 0.07508249580860138, \n",
      "training actor, critic...\n",
      "actor loss: 8.04267692565918, critic loss: 0.07526586204767227\n",
      "2024-10-04 10:36:04,564 global_step: 328,epoch: 16, kl_loss: 0.0011776730686079292, reconst_loss: 0.005491514405121608, reward_loss: 0.10548504932465184, actor_loss: 8.04267692565918, critic_loss: 0.07526586204767227, \n",
      "training actor, critic...\n",
      "actor loss: 8.065862655639648, critic loss: 0.07796981930732727\n",
      "2024-10-04 10:36:13,978 global_step: 329,epoch: 16, kl_loss: 0.0012731412015807796, reconst_loss: 0.006696062238544834, reward_loss: 0.14224276381689693, actor_loss: 8.065862655639648, critic_loss: 0.07796981930732727, \n",
      "training actor, critic...\n",
      "actor loss: 8.066625595092773, critic loss: 0.07833319157361984\n",
      "2024-10-04 10:36:23,539 global_step: 330,epoch: 16, kl_loss: 0.0012322621077313373, reconst_loss: 0.006786015454907806, reward_loss: 0.1570244932663627, actor_loss: 8.066625595092773, critic_loss: 0.07833319157361984, \n",
      "training actor, critic...\n",
      "actor loss: 8.044600486755371, critic loss: 0.07657130062580109\n",
      "2024-10-04 10:36:32,839 global_step: 331,epoch: 16, kl_loss: 0.0011720121674814584, reconst_loss: 0.00564291838518515, reward_loss: 0.11337828864010849, actor_loss: 8.044600486755371, critic_loss: 0.07657130062580109, \n",
      "training actor, critic...\n",
      "actor loss: 8.00217056274414, critic loss: 0.07745654881000519\n",
      "2024-10-04 10:36:42,197 global_step: 332,epoch: 16, kl_loss: 0.0012367359714164417, reconst_loss: 0.005140329169451582, reward_loss: 0.07691491629491198, actor_loss: 8.00217056274414, critic_loss: 0.07745654881000519, \n",
      "training actor, critic...\n",
      "actor loss: 7.935262680053711, critic loss: 0.07595822215080261\n",
      "2024-10-04 10:36:51,341 global_step: 333,epoch: 16, kl_loss: 0.0012568202952507465, reconst_loss: 0.006983362204794373, reward_loss: 0.13629548184155504, actor_loss: 7.935262680053711, critic_loss: 0.07595822215080261, \n",
      "training actor, critic...\n",
      "actor loss: 7.852334022521973, critic loss: 0.07050054520368576\n",
      "2024-10-04 10:37:00,462 global_step: 334,epoch: 16, kl_loss: 0.0011558970008805698, reconst_loss: 0.005066947479333196, reward_loss: 0.09680597989330525, actor_loss: 7.852334022521973, critic_loss: 0.07050054520368576, \n",
      "training actor, critic...\n",
      "actor loss: 7.762764930725098, critic loss: 0.0672333762049675\n",
      "2024-10-04 10:37:09,779 global_step: 335,epoch: 16, kl_loss: 0.0011671889823984963, reconst_loss: 0.004215926635174119, reward_loss: 0.06307703832031361, actor_loss: 7.762764930725098, critic_loss: 0.0672333762049675, \n",
      "training actor, critic...\n",
      "actor loss: 7.669504642486572, critic loss: 0.06657149642705917\n",
      "2024-10-04 10:37:18,982 global_step: 336,epoch: 16, kl_loss: 0.001192865098531985, reconst_loss: 0.005125112993148517, reward_loss: 0.09982655552211123, actor_loss: 7.669504642486572, critic_loss: 0.06657149642705917, \n",
      "training actor, critic...\n",
      "actor loss: 7.58135986328125, critic loss: 0.06466707587242126\n",
      "2024-10-04 10:37:28,172 global_step: 337,epoch: 16, kl_loss: 0.0011755741624237628, reconst_loss: 0.005491110980890843, reward_loss: 0.11013637777722003, actor_loss: 7.58135986328125, critic_loss: 0.06466707587242126, \n",
      "training actor, critic...\n",
      "actor loss: 7.509685039520264, critic loss: 0.06227775663137436\n",
      "2024-10-04 10:37:37,346 global_step: 338,epoch: 16, kl_loss: 0.0011896946516757527, reconst_loss: 0.004216868102512494, reward_loss: 0.07839125276623977, actor_loss: 7.509685039520264, critic_loss: 0.06227775663137436, \n",
      "training actor, critic...\n",
      "actor loss: 7.45572566986084, critic loss: 0.060762450098991394\n",
      "2024-10-04 10:37:46,452 global_step: 339,epoch: 16, kl_loss: 0.001169868249253712, reconst_loss: 0.005193604332185826, reward_loss: 0.1167850185171416, actor_loss: 7.45572566986084, critic_loss: 0.060762450098991394, \n",
      "collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:35<00:00, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-04 10:38:22,248 global_step: 340,train_score: -92.85945259883488, \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "batch_size = 64\n",
    "seq_len = 50\n",
    "\n",
    "world_episodes = 3\n",
    "update_step = 20\n",
    "\n",
    "seed_episodes = 5\n",
    "test_interval = 3\n",
    "save_interval = 20\n",
    "print(\"collecting seed data...\")\n",
    "collect_data(env,state_dim, transition_representation, agent, replay_buffer, seed_episodes, device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_score=collect_data(env,state_dim, transition_representation, agent, replay_buffer, world_episodes, device)\n",
    "    logger.log(epoch*update_step,train_score=train_score)\n",
    "\n",
    "    if len(replay_buffer) < batch_size*seq_len:\n",
    "        continue\n",
    "    print(len(replay_buffer))\n",
    "    \n",
    "    #train world model and actor, critic\n",
    "    for _ in range(update_step):\n",
    "        batch = replay_buffer.sample_seq(batch_size, seq_len)\n",
    "        kl_loss,reconst_loss, reward_loss, actor_loss, critic_loss=train(batch,state_dim,deterministic_dim, device, transition_representation, reward, observation, agent, value, model_optimizer, actor_optimizer, critic_optimizer)\n",
    "        logger.log(epoch*update_step+_,epoch=epoch, kl_loss=kl_loss, reconst_loss=reconst_loss, reward_loss=reward_loss, actor_loss=actor_loss, critic_loss=critic_loss)\n",
    "\n",
    "    if epoch % test_interval == 0:\n",
    "        test_score=collect_data(env,state_dim, transition_representation, agent, replay_buffer, world_episodes, device,training=False)\n",
    "        logger.log(epoch*update_step,test_score=test_score)\n",
    "    if epoch % save_interval == 0:\n",
    "        torch.save(transition_representation.state_dict(), 'transition_representation.pth')\n",
    "        torch.save(observation.state_dict(), 'observation.pth')\n",
    "        torch.save(reward.state_dict(), 'reward.pth')\n",
    "        torch.save(agent.state_dict(), 'agent.pth')\n",
    "        torch.save(value.state_dict(), 'value.pth')\n",
    "torch.save(transition_representation.state_dict(), 'transition_representation.pth')\n",
    "torch.save(observation.state_dict(), 'observation.pth')\n",
    "torch.save(reward.state_dict(), 'reward.pth')\n",
    "torch.save(agent.state_dict(), 'agent.pth')\n",
    "torch.save(value.state_dict(), 'value.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
